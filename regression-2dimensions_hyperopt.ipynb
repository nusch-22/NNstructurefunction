{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import yaml\n",
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "from pathlib import Path\n",
    "from filetrials import FileTrials, space_eval\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.callbacks import Callback, EarlyStopping\n",
    "\n",
    "# Import hyperopt modules\n",
    "from hyperopt import hp, fmin, tpe\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix the seeds for reproducible results\n",
    "tf.random.set_seed(1234)\n",
    "np.random.seed(5678)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_path = Path().absolute()\n",
    "hyperopt_path = current_path\n",
    "fits_path = current_path / \"fits\"\n",
    "fits_path.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load runcard with parameters\n",
    "def load_runcard(filename):\n",
    "    with open(f\"{current_path}/\" + filename, \"r\") as file:\n",
    "        input_params = yaml.safe_load(file)\n",
    "    return input_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_trval(x_data, y_data, y_err_stat, y_err_sys, perc = 0.3):\n",
    "    size_val = round(x_data.shape[0]*perc)\n",
    "    idx = np.random.choice(np.arange(1, x_data.shape[0]-1, 2), size_val, replace=False)\n",
    "    x_val = x_data[idx]\n",
    "    y_val = y_data[idx]\n",
    "    y_val_err_stat = y_err_stat[idx]\n",
    "    y_val_err_sys = y_err_sys[idx]\n",
    "    \n",
    "    x_tr = np.delete(x_data, idx, axis = 0)\n",
    "    y_tr = np.delete(y_data, idx)\n",
    "    y_tr_err_stat = np.delete(y_err_stat, idx)\n",
    "    y_tr_err_sys = np.delete(y_err_sys, idx)\n",
    "    \n",
    "    return x_tr, y_tr, y_tr_err_stat, y_tr_err_sys, x_val, y_val, y_val_err_stat, y_val_err_sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(runcard):\n",
    "    filenames = os.listdir(f\"{current_path}/data\")\n",
    "\n",
    "    x_sep_data = []\n",
    "    y_sep_data = []\n",
    "\n",
    "    for i, filename in enumerate(filenames):\n",
    "        with open(f\"{current_path}/data/\" + filename, \"r\") as file:\n",
    "            input_data = yaml.safe_load(file)\n",
    "\n",
    "        x = input_data[\"x\"]\n",
    "        Q2 = np.array(input_data[\"Q2\"])\n",
    "        F_2 = np.array(input_data[\"F_2\"])\n",
    "        F_2_err_stat = np.array(input_data[\"F_2_err_stat\"])\n",
    "        F_2_err_sys = np.array(input_data[\"F_2_err_sys\"])\n",
    "\n",
    "        if runcard[\"Q2_cut\"] != None:\n",
    "            Q2_mask = np.where(Q2 < runcard[\"Q2_cut\"])\n",
    "            Q2 = Q2[Q2_mask]\n",
    "            F_2 = F_2[Q2_mask]\n",
    "            F_2_err_stat = F_2_err_stat[Q2_mask]\n",
    "            F_2_err_sys = F_2_err_sys[Q2_mask]\n",
    "\n",
    "        if i == 0:\n",
    "            x_data = np.zeros((len(Q2), 2))\n",
    "            x_data[:, 0] = x\n",
    "            x_data[:, 1] = Q2\n",
    "            y_data = F_2\n",
    "            x_sep_data.append(x_data)\n",
    "            y_sep_data.append(y_data)\n",
    "            y_err_stat = F_2_err_stat\n",
    "            y_err_sys = F_2_err_sys\n",
    "            \n",
    "            if x_data.shape[0] >= 3:\n",
    "                x_tr, y_tr, y_tr_err_stat, y_tr_err_sys, x_val, y_val, y_val_err_stat, y_val_err_sys = split_trval(x_data, y_data, y_err_stat, y_err_sys, perc=runcard[\"validation_size\"])\n",
    "                #import pdb;pdb.set_trace()\n",
    "                val = True\n",
    "            else:\n",
    "                x_tr = x_data\n",
    "                y_tr = y_data\n",
    "                y_tr_err_stat = y_err_stat\n",
    "                y_tr_err_sys = y_err_sys\n",
    "                val = False\n",
    "        else:\n",
    "            x_data_new = np.zeros((len(Q2), 2))\n",
    "            x_data_new[:, 0] = x\n",
    "            x_data_new[:, 1] = Q2\n",
    "            y_data_new = F_2\n",
    "            y_err_stat_new = F_2_err_stat\n",
    "            y_err_sys_new = F_2_err_sys\n",
    "            \n",
    "            \n",
    "            if x_data_new.shape[0] >= 3:\n",
    "                x_tr_new, y_tr_new, y_tr_err_stat_new, y_tr_err_sys_new, x_val_new, y_val_new, y_val_err_stat_new, y_val_err_sys_new = split_trval(\n",
    "                    x_data_new, y_data_new, y_err_stat_new, y_err_sys_new, perc=runcard[\"validation_size\"]\n",
    "                )\n",
    "                if val:\n",
    "                    x_val = np.concatenate([x_val, x_val_new], axis=0)\n",
    "                    y_val = np.concatenate([y_val, y_val_new], axis=0)\n",
    "                    y_val_err_stat = np.concatenate([y_val_err_stat, y_val_err_stat_new], axis=0)\n",
    "                    y_val_err_sys = np.concatenate([y_val_err_sys, y_val_err_sys_new], axis=0)\n",
    "                else:\n",
    "                    x_val = x_val_new\n",
    "                    y_val = y_val_new\n",
    "                    y_val_err_stat = y_val_err_stat_new\n",
    "                    y_val_err_sys = y_val_err_sys_new\n",
    "                    val = True\n",
    "                \n",
    "            else:\n",
    "                x_tr_new = x_data_new\n",
    "                y_tr_new = y_data_new\n",
    "                y_tr_err_stat_new = y_err_stat_new\n",
    "                y_tr_err_sys_new = y_err_sys_new\n",
    "\n",
    "            x_tr = np.concatenate([x_tr, x_tr_new], axis=0)\n",
    "            y_tr = np.concatenate([y_tr, y_tr_new], axis=0)\n",
    "            y_tr_err_stat = np.concatenate([y_tr_err_stat, y_tr_err_stat_new], axis=0)\n",
    "            y_tr_err_sys = np.concatenate([y_tr_err_sys, y_tr_err_sys_new], axis=0)\n",
    "            \n",
    "            y_err_stat = np.concatenate([y_err_stat, y_err_stat_new], axis=0)\n",
    "            y_err_sys = np.concatenate([y_err_sys, y_err_sys_new], axis=0)\n",
    "            x_sep_data.append(x_data_new)\n",
    "            y_sep_data.append(y_data_new)\n",
    "            x_data = np.concatenate([x_data, x_data_new], axis=0)\n",
    "            y_data = np.concatenate([y_data, y_data_new], axis=0)\n",
    "\n",
    "    return {\n",
    "        \"x_tr\": x_tr,\n",
    "        \"y_tr\": y_tr,\n",
    "        \"y_tr_err_stat\": y_tr_err_stat,\n",
    "        \"y_tr_err_sys\": y_tr_err_sys,\n",
    "        \"x_val\": x_val,\n",
    "        \"y_val\": y_val,\n",
    "        \"y_val_err_stat\": y_val_err_stat,\n",
    "        \"y_val_err_sys\": y_val_err_sys,\n",
    "        \"x_data\": x_data,\n",
    "        \"y_data\": y_data,\n",
    "        \"y_err_stat\": y_err_stat,\n",
    "        \"y_err_sys\": y_err_sys,\n",
    "        \"x_sep_data\": x_sep_data,\n",
    "        \"y_sep_data\": y_sep_data,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_covmat(data_dict):\n",
    "    covmat_tr = np.zeros((data_dict[\"y_tr\"].shape[0], data_dict[\"y_tr\"].shape[0]))\n",
    "    for i in range(data_dict[\"y_tr\"].shape[0]):\n",
    "        for j in range(data_dict[\"y_tr\"].shape[0]):\n",
    "            covmat_tr[i, j] = (\n",
    "                data_dict[\"y_tr_err_sys\"][i] * data_dict[\"y_tr_err_sys\"][j]\n",
    "                + data_dict[\"y_tr\"][i] * data_dict[\"y_tr\"][j]\n",
    "            )\n",
    "            if i == j:\n",
    "                covmat_tr[i, j] += data_dict[\"y_tr_err_stat\"][i] ** 2\n",
    "                \n",
    "    covmat_val = np.zeros((data_dict[\"y_val\"].shape[0], data_dict[\"y_val\"].shape[0]))\n",
    "    for i in range(data_dict[\"y_val\"].shape[0]):\n",
    "        for j in range(data_dict[\"y_val\"].shape[0]):\n",
    "            covmat_val[i, j] = (\n",
    "                data_dict[\"y_val_err_sys\"][i] * data_dict[\"y_val_err_sys\"][j]\n",
    "                + data_dict[\"y_val\"][i] * data_dict[\"y_val\"][j]\n",
    "            )\n",
    "            if i == j:\n",
    "                covmat_val[i, j] += data_dict[\"y_val_err_stat\"][i] ** 2\n",
    "    \n",
    "    return {\"tr\": covmat_tr, \"val\": covmat_val}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chi2_with_covmat(covmat, ndata):\n",
    "    inverted_tr = np.linalg.inv(covmat[\"tr\"])\n",
    "    inverted_val = np.linalg.inv(covmat[\"val\"])\n",
    "    ndata_tr = ndata[\"tr\"]\n",
    "    ndata_val = ndata[\"val\"]\n",
    "    # Convert numpy array into tensorflow object\n",
    "    invcovmat_tr = K.constant(inverted_tr)\n",
    "    invcovmat_val = K.constant(inverted_val)\n",
    "\n",
    "    def custom_loss(y_true, y_pred):\n",
    "        # (yt - yp) * covmat * (yt - yp)\n",
    "        tmp = y_true - y_pred\n",
    "        import pdb; pdb.set_trace()\n",
    "        try:\n",
    "            tmp = y_true - y_pred\n",
    "            right_dot = tf.tensordot(invcovmat_val, K.transpose(tmp), axes=1)\n",
    "            return tf.tensordot(tmp, right_dot, axes=1) / ndata_val\n",
    "        \n",
    "        except:\n",
    "            right_dot = tf.tensordot(invcovmat_tr, K.transpose(tmp), axes=1)\n",
    "            return tf.tensordot(tmp, right_dot, axes=1) / ndata_tr\n",
    "        \n",
    "\n",
    "    return custom_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m/tmp/tmpiwf3ip16.py\u001b[0m(14)\u001b[0;36mtf__custom_loss\u001b[0;34m()\u001b[0m         \n",
      "\u001b[0;32m     12 \u001b[0;31m                \u001b[0;32mimport\u001b[0m \u001b[0mpdb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     13 \u001b[0;31m                \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpdb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m---> 14 \u001b[0;31m                \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     15 \u001b[0;31m                    \u001b[0mtmp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     16 \u001b[0;31m                    \u001b[0mright_dot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensordot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minvcovmat_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtmp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "  0%|                                     | 0/2 [00:00<?, ?trial/s, best loss=?]ipdb> c\n",
      "> \u001b[0;32m/tmp/tmpiwf3ip16.py\u001b[0m(14)\u001b[0;36mtf__custom_loss\u001b[0;34m()\u001b[0m         \n",
      "\u001b[0;32m     12 \u001b[0;31m                \u001b[0;32mimport\u001b[0m \u001b[0mpdb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     13 \u001b[0;31m                \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpdb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m---> 14 \u001b[0;31m                \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     15 \u001b[0;31m                    \u001b[0mtmp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     16 \u001b[0;31m                    \u001b[0mright_dot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensordot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minvcovmat_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtmp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "  0%|                                     | 0/2 [00:02<?, ?trial/s, best loss=?]ipdb> c\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "job exception:  Matrix size-incompatible: In[0]: [19,19], In[1]: [1,32]\n",
      "\t [[node custom_loss/Tensordot/MatMul (defined at tmp/ipykernel_3806/2998002762.py:13) ]] [Op:__inference_train_function_1791]\n",
      "\n",
      "Function call stack:\n",
      "train_function\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|                                     | 0/2 [00:03<?, ?trial/s, best loss=?]\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": " Matrix size-incompatible: In[0]: [19,19], In[1]: [1,32]\n\t [[node custom_loss/Tensordot/MatMul (defined at tmp/ipykernel_3806/2998002762.py:13) ]] [Op:__inference_train_function_1791]\n\nFunction call stack:\ntrain_function\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_3806/1671200262.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mbest_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mperform_hyperopt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mruncard\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_3806/290507074.py\u001b[0m in \u001b[0;36mperform_hyperopt\u001b[0;34m(data_dict, runcard)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mtrials\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFileTrials\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhyperopt_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhyperspace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     best = fmin(\n\u001b[0m\u001b[1;32m     11\u001b[0m         \u001b[0mfn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhyper_function\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mspace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhyperspace\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/nnpdf40/lib/python3.9/site-packages/hyperopt/fmin.py\u001b[0m in \u001b[0;36mfmin\u001b[0;34m(fn, space, algo, max_evals, timeout, loss_threshold, trials, rstate, allow_trials_fmin, pass_expr_memo_ctrl, catch_eval_exceptions, verbose, return_argmin, points_to_evaluate, max_queue_len, show_progressbar, early_stop_fn, trials_save_file)\u001b[0m\n\u001b[1;32m    505\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mallow_trials_fmin\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrials\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"fmin\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 507\u001b[0;31m         return trials.fmin(\n\u001b[0m\u001b[1;32m    508\u001b[0m             \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    509\u001b[0m             \u001b[0mspace\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/nnpdf40/lib/python3.9/site-packages/hyperopt/base.py\u001b[0m in \u001b[0;36mfmin\u001b[0;34m(self, fn, space, algo, max_evals, timeout, loss_threshold, max_queue_len, rstate, verbose, pass_expr_memo_ctrl, catch_eval_exceptions, return_argmin, show_progressbar, early_stop_fn, trials_save_file)\u001b[0m\n\u001b[1;32m    680\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mfmin\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfmin\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    681\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 682\u001b[0;31m         return fmin(\n\u001b[0m\u001b[1;32m    683\u001b[0m             \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    684\u001b[0m             \u001b[0mspace\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/nnpdf40/lib/python3.9/site-packages/hyperopt/fmin.py\u001b[0m in \u001b[0;36mfmin\u001b[0;34m(fn, space, algo, max_evals, timeout, loss_threshold, trials, rstate, allow_trials_fmin, pass_expr_memo_ctrl, catch_eval_exceptions, verbose, return_argmin, points_to_evaluate, max_queue_len, show_progressbar, early_stop_fn, trials_save_file)\u001b[0m\n\u001b[1;32m    551\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m     \u001b[0;31m# next line is where the fmin is actually executed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 553\u001b[0;31m     \u001b[0mrval\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexhaust\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    555\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreturn_argmin\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/nnpdf40/lib/python3.9/site-packages/hyperopt/fmin.py\u001b[0m in \u001b[0;36mexhaust\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    354\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mexhaust\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    355\u001b[0m         \u001b[0mn_done\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 356\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_evals\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mn_done\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mblock_until_done\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masynchronous\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    357\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrefresh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/nnpdf40/lib/python3.9/site-packages/hyperopt/fmin.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, N, block_until_done)\u001b[0m\n\u001b[1;32m    290\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m                     \u001b[0;31m# -- loop over trials and do the jobs directly\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 292\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mserial_evaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    293\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrefresh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/nnpdf40/lib/python3.9/site-packages/hyperopt/fmin.py\u001b[0m in \u001b[0;36mserial_evaluate\u001b[0;34m(self, N)\u001b[0m\n\u001b[1;32m    168\u001b[0m                 \u001b[0mctrl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbase\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCtrl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcurrent_trial\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 170\u001b[0;31m                     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdomain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctrl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    171\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m                     \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"job exception: %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/nnpdf40/lib/python3.9/site-packages/hyperopt/base.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, config, ctrl, attach_attachments)\u001b[0m\n\u001b[1;32m    905\u001b[0m                 \u001b[0mprint_node_on_error\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrec_eval_print_node_on_error\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    906\u001b[0m             )\n\u001b[0;32m--> 907\u001b[0;31m             \u001b[0mrval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpyll_rval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    908\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    909\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumber\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_3806/290507074.py\u001b[0m in \u001b[0;36mhyper_function\u001b[0;34m(hyperspace_dict)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;31m# Define the hyperoptimization function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mhyper_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhyperspace_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_trainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mruncard\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mhyperspace_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"loss\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mval_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"status\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"ok\"\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_3806/3716700897.py\u001b[0m in \u001b[0;36mmodel_trainer\u001b[0;34m(data_dict, runcard, **hyperparameters)\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0;31m# Fit the Model as usual\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m     model.fit(\n\u001b[0m\u001b[1;32m     39\u001b[0m         \u001b[0mdata_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"x_tr\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0mdata_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"y_tr\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/nnpdf40/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 _r=1):\n\u001b[1;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/nnpdf40/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/nnpdf40/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    886\u001b[0m         \u001b[0;31m# Lifting succeeded, so variables are initialized and we can run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    887\u001b[0m         \u001b[0;31m# stateless function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 888\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    889\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    890\u001b[0m       \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfiltered_flat_args\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/nnpdf40/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2940\u001b[0m       (graph_function,\n\u001b[1;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2942\u001b[0;31m     return graph_function._call_flat(\n\u001b[0m\u001b[1;32m   2943\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m   2944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/nnpdf40/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1916\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1917\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1918\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1919\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m~/anaconda3/envs/nnpdf40/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    553\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    554\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 555\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    556\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    557\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/nnpdf40/lib/python3.9/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m:  Matrix size-incompatible: In[0]: [19,19], In[1]: [1,32]\n\t [[node custom_loss/Tensordot/MatMul (defined at tmp/ipykernel_3806/2998002762.py:13) ]] [Op:__inference_train_function_1791]\n\nFunction call stack:\ntrain_function\n"
     ]
    }
   ],
   "source": [
    "best_params = perform_hyperopt(data_dict, runcard)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_trainer(data_dict, runcard, **hyperparameters):\n",
    "    # Collect the values for the hyperparameters\n",
    "    optimizer = hyperparameters.get(\"optimizer\", \"adam\")\n",
    "    activation = hyperparameters.get(\"activation\", \"relu\")\n",
    "    epochs = hyperparameters.get(\"epochs\", 10)\n",
    "    nb_layers = hyperparameters.get(\"nb_layers\", (2, {'units_layer_1_2': 64, 'units_layer_2_2': 32}))\n",
    "    \n",
    "    layers = list(nb_layers[1].keys())\n",
    "    nb_units_1 = nb_layers[1][layers[0]]\n",
    "\n",
    "    # Construct the model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(units=nb_units_1, activation=activation, input_shape=[2]))\n",
    "    \n",
    "    if nb_layers[0] > 1:\n",
    "        for layer in layers[1:]:\n",
    "            model.add(Dense(units=nb_layers[1][layer], activation=activation))\n",
    "    \n",
    "    # output layer\n",
    "    model.add(Dense(units=1, activation=\"linear\"))\n",
    "\n",
    "    # Compile the Model as usual\n",
    "    ndata = {\"tr\": data_dict[\"y_tr\"].shape[0], \"val\": data_dict[\"y_val\"].shape[0]}\n",
    "    covmat = compute_covmat(data_dict)\n",
    "    model.compile(loss=chi2_with_covmat(covmat, ndata), optimizer=optimizer, metrics=[\"accuracy\"])\n",
    "    #model.compile(loss=\"mse\", optimizer=optimizer, metrics=[\"accuracy\"])\n",
    "\n",
    "    # Callbacks for Early Stopping\n",
    "    ES = EarlyStopping(\n",
    "        monitor=\"val_loss\",\n",
    "        mode=\"min\",\n",
    "        verbose=0,\n",
    "        patience=10,\n",
    "        restore_best_weights=True,\n",
    "    )\n",
    "\n",
    "    # Fit the Model as usual\n",
    "    model.fit(\n",
    "        data_dict[\"x_tr\"],\n",
    "        data_dict[\"y_tr\"],\n",
    "        validation_data=(data_dict[\"x_val\"], data_dict[\"y_val\"]),\n",
    "        epochs=epochs,\n",
    "        verbose=0,\n",
    "        callbacks=[ES],\n",
    "    )\n",
    "\n",
    "    # Evaluate the Model on the test. Note that this will be the\n",
    "    # parameter to hyperoptimize. If one wants, one could use x/y_tr.\n",
    "    # This might be ideal if one have very small number of datapoints\n",
    "    scores = model.evaluate(data_dict[\"x_val\"], data_dict[\"y_val\"], verbose=0)\n",
    "    # Return the value of the validation loss\n",
    "    return model, scores[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_layers_dict(runcard):\n",
    "    layers_list = []\n",
    "    nb_units_per_layer = runcard[\"nb_units_per_layer\"]\n",
    "    for n in runcard[\"layers_choices\"]:\n",
    "        layer_dict = {}\n",
    "        for i in range(1, n+1):\n",
    "            key = f\"units_layer_{i}_{n}\"\n",
    "            layer_dict[f\"units_layer_{i}\"] = hp.quniform(key, nb_units_per_layer[\"min\"], nb_units_per_layer[\"max\"], nb_units_per_layer[\"samples\"])\n",
    "        layers_list.append((n, layer_dict))\n",
    "    return hp.choice(\"nb_layers\", layers_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_hyperspace(runcard):\n",
    "    learning_rate_choices = runcard[\"learning_rate_choices\"]\n",
    "    activation = hp.choice(\"activation\", runcard[\"activation_choices\"])\n",
    "    optimizer = hp.choice(\"optimizer\", runcard[\"optimizer_choices\"])\n",
    "    epochs = hp.choice(\"epochs\", runcard[\"epochs_choices\"])\n",
    "    initializer = hp.choice(\"initializer\", runcard[\"initializer_choices\"])\n",
    "    learning_rate = hp.loguniform(\"learning_rate\", float(learning_rate_choices[\"min\"]), float(learning_rate_choices[\"max\"]))\n",
    "    nb_layers = construct_layers_dict(runcard)\n",
    "    \n",
    "    return {\n",
    "        \"activation\": activation,\n",
    "        \"optimizer\": optimizer,\n",
    "        \"epochs\": epochs,\n",
    "        \"initializer\": initializer,\n",
    "        \"learning_rate\": learning_rate,\n",
    "        \"nb_layers\": nb_layers\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_hyperopt(data_dict, runcard):\n",
    "    hyperspace = define_hyperspace(runcard)\n",
    "\n",
    "    # Define the hyperoptimization function\n",
    "    def hyper_function(hyperspace_dict):\n",
    "        _, val_loss = model_trainer(data_dict, runcard, **hyperspace_dict)\n",
    "        return {\"loss\": val_loss, \"status\": \"ok\"}\n",
    "\n",
    "    trials = FileTrials(hyperopt_path, parameters=hyperspace)\n",
    "    best = fmin(\n",
    "        fn=hyper_function,\n",
    "        space=hyperspace,\n",
    "        verbose=1,\n",
    "        max_evals=runcard[\"nb_trials\"],\n",
    "        algo=tpe.suggest,\n",
    "        trials=trials,\n",
    "    )\n",
    "    # Save the best hyperparameters combination in order to return it later\n",
    "    best_setup = space_eval(hyperspace, best)\n",
    "    # Write the output of the best into a file\n",
    "    with open(f\"{hyperopt_path}/best_hyperparameters.yaml\", \"w\") as file:\n",
    "        yaml.dump(best_setup, file, default_flow_style=False)\n",
    "    # Write the all the history of the hyperopt into a file\n",
    "    with open(f\"{hyperopt_path}/hyperopt_history.pickle\", \"wb\") as histfile:\n",
    "        pickle.dump(trials.trials, histfile)\n",
    "    return best_setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_constant_x(best_model, data_dict):\n",
    "    # loop over x values\n",
    "    for i in range(len(data_dict[\"x_sep_data\"])):\n",
    "        x = data_dict[\"x_sep_data\"][i]\n",
    "        y = data_dict[\"y_sep_data\"][i]\n",
    "        x_grid = np.linspace(x[0], x[-1], 100)\n",
    "        y_pred = best_model(x_grid)\n",
    "        \n",
    "        fig, ax = plt.subplots(1, 1) \n",
    "        ax.plot(x_grid[:, 1], y_pred, color=\"red\", label=\"Prediction\")\n",
    "        ax.scatter(x[:, 1], y, color=\"blue\", label=\"Data\")\n",
    "        ax.legend()\n",
    "        ax.set_xlabel(\"$Q^2$ [GeV$^2$]\")\n",
    "        ax.set_ylabel(\"$F_2$\")\n",
    "        ax.set_title(f\"Prediction of $F_2$ at $x={x[0,0]}$\")\n",
    "        plt.show()\n",
    "        plt.savefig(f\"{fits_path}/FIT_{x[0,0]}.png\")\n",
    "        ax.clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "runcard = load_runcard(\"runcard.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict = load_data(runcard)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model,_ = model_trainer(data_dict, runcard, **best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_constant_x(best_model, data_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ADD Inputs runcard:\n",
    "\n",
    "Add hyperopt nb layers\n",
    "\n",
    "Seperate scripts:\n",
    "- hyperopt (combine with filetrials?)\n",
    "- training (option replicas)\n",
    "- plotting\n",
    "\n",
    "filetrials.py:\n",
    "- change path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "51b07192feadff41234e4986821c542e33f28bd852adab907add648296a24759"
  },
  "kernelspec": {
   "display_name": "nnpdf40",
   "language": "python",
   "name": "nnpdf40"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
