{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import yaml\n",
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "from pathlib import Path\n",
    "from filetrials import FileTrials, space_eval\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.callbacks import Callback, EarlyStopping\n",
    "\n",
    "# Import hyperopt modules\n",
    "from hyperopt import hp, fmin, tpe\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix the seeds for reproducible results\n",
    "tf.random.set_seed(1234)\n",
    "np.random.seed(5678)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_path = Path().absolute()\n",
    "hyperopt_path = current_path\n",
    "fits_path = current_path / \"fits\"\n",
    "fits_path.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load runcard with parameters\n",
    "def load_runcard(filename):\n",
    "    with open(f\"{current_path}/\" + filename, \"r\") as file:\n",
    "        input_params = yaml.safe_load(file)\n",
    "    return input_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_trval(x_data, y_data, y_err_stat, y_err_sys, perc = 0.3):\n",
    "    size_val = round(x_data.shape[0]*perc)\n",
    "    idx = np.random.choice(np.arange(1, x_data.shape[0]-1, 2), size_val, replace=False)\n",
    "    x_val = x_data[idx]\n",
    "    y_val = y_data[idx]\n",
    "    y_val_err_stat = y_err_stat[idx]\n",
    "    y_val_err_sys = y_err_sys[idx]\n",
    "    \n",
    "    x_tr = np.delete(x_data, idx, axis = 0)\n",
    "    y_tr = np.delete(y_data, idx)\n",
    "    y_tr_err_stat = np.delete(y_err_stat, idx)\n",
    "    y_tr_err_sys = np.delete(y_err_sys, idx)\n",
    "    \n",
    "    return x_tr, y_tr, y_tr_err_stat, y_tr_err_sys, x_val, y_val, y_val_err_stat, y_val_err_sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(runcard):\n",
    "    filenames = os.listdir(f\"{current_path}/data\")\n",
    "\n",
    "    x_sep_data = []\n",
    "    y_sep_data = []\n",
    "\n",
    "    for i, filename in enumerate(filenames):\n",
    "        with open(f\"{current_path}/data/\" + filename, \"r\") as file:\n",
    "            input_data = yaml.safe_load(file)\n",
    "\n",
    "        x = input_data[\"x\"]\n",
    "        Q2 = np.array(input_data[\"Q2\"])\n",
    "        F_2 = np.array(input_data[\"F_2\"])\n",
    "        F_2_err_stat = np.array(input_data[\"F_2_err_stat\"])\n",
    "        F_2_err_sys = np.array(input_data[\"F_2_err_sys\"])\n",
    "\n",
    "        if runcard[\"Q2_cut\"] != None:\n",
    "            Q2_mask = np.where(Q2 < runcard[\"Q2_cut\"])\n",
    "            Q2 = Q2[Q2_mask]\n",
    "            F_2 = F_2[Q2_mask]\n",
    "            F_2_err_stat = F_2_err_stat[Q2_mask]\n",
    "            F_2_err_sys = F_2_err_sys[Q2_mask]\n",
    "\n",
    "        if i == 0:\n",
    "            x_data = np.zeros((len(Q2), 2))\n",
    "            x_data[:, 0] = x\n",
    "            x_data[:, 1] = Q2\n",
    "            y_data = F_2\n",
    "            x_sep_data.append(x_data)\n",
    "            y_sep_data.append(y_data)\n",
    "            y_err_stat = F_2_err_stat\n",
    "            y_err_sys = F_2_err_sys\n",
    "            \n",
    "            if x_data.shape[0] >= 3:\n",
    "                x_tr, y_tr, y_tr_err_stat, y_tr_err_sys, x_val, y_val, y_val_err_stat, y_val_err_sys = split_trval(x_data, y_data, y_err_stat, y_err_sys, perc=runcard[\"validation_size\"])\n",
    "                #import pdb;pdb.set_trace()\n",
    "                val = True\n",
    "            else:\n",
    "                x_tr = x_data\n",
    "                y_tr = y_data\n",
    "                y_tr_err_stat = y_err_stat\n",
    "                y_tr_err_sys = y_err_sys\n",
    "                val = False\n",
    "        else:\n",
    "            x_data_new = np.zeros((len(Q2), 2))\n",
    "            x_data_new[:, 0] = x\n",
    "            x_data_new[:, 1] = Q2\n",
    "            y_data_new = F_2\n",
    "            y_err_stat_new = F_2_err_stat\n",
    "            y_err_sys_new = F_2_err_sys\n",
    "            \n",
    "            \n",
    "            if x_data_new.shape[0] >= 3:\n",
    "                x_tr_new, y_tr_new, y_tr_err_stat_new, y_tr_err_sys_new, x_val_new, y_val_new, y_val_err_stat_new, y_val_err_sys_new = split_trval(\n",
    "                    x_data_new, y_data_new, y_err_stat_new, y_err_sys_new, perc=runcard[\"validation_size\"]\n",
    "                )\n",
    "                if val:\n",
    "                    x_val = np.concatenate([x_val, x_val_new], axis=0)\n",
    "                    y_val = np.concatenate([y_val, y_val_new], axis=0)\n",
    "                    y_val_err_stat = np.concatenate([y_val_err_stat, y_val_err_stat_new], axis=0)\n",
    "                    y_val_err_sys = np.concatenate([y_val_err_sys, y_val_err_sys_new], axis=0)\n",
    "                else:\n",
    "                    x_val = x_val_new\n",
    "                    y_val = y_val_new\n",
    "                    y_val_err_stat = y_val_err_stat_new\n",
    "                    y_val_err_sys = y_val_err_sys_new\n",
    "                    val = True\n",
    "                \n",
    "            else:\n",
    "                x_tr_new = x_data_new\n",
    "                y_tr_new = y_data_new\n",
    "                y_tr_err_stat_new = y_err_stat_new\n",
    "                y_tr_err_sys_new = y_err_sys_new\n",
    "\n",
    "            x_tr = np.concatenate([x_tr, x_tr_new], axis=0)\n",
    "            y_tr = np.concatenate([y_tr, y_tr_new], axis=0)\n",
    "            y_tr_err_stat = np.concatenate([y_tr_err_stat, y_tr_err_stat_new], axis=0)\n",
    "            y_tr_err_sys = np.concatenate([y_tr_err_sys, y_tr_err_sys_new], axis=0)\n",
    "            \n",
    "            y_err_stat = np.concatenate([y_err_stat, y_err_stat_new], axis=0)\n",
    "            y_err_sys = np.concatenate([y_err_sys, y_err_sys_new], axis=0)\n",
    "            x_sep_data.append(x_data_new)\n",
    "            y_sep_data.append(y_data_new)\n",
    "            x_data = np.concatenate([x_data, x_data_new], axis=0)\n",
    "            y_data = np.concatenate([y_data, y_data_new], axis=0)\n",
    "\n",
    "    return {\n",
    "        \"x_tr\": x_tr,\n",
    "        \"y_tr\": y_tr,\n",
    "        \"y_tr_err_stat\": y_tr_err_stat,\n",
    "        \"y_tr_err_sys\": y_tr_err_sys,\n",
    "        \"x_val\": x_val,\n",
    "        \"y_val\": y_val,\n",
    "        \"y_val_err_stat\": y_val_err_stat,\n",
    "        \"y_val_err_sys\": y_val_err_sys,\n",
    "        \"x_data\": x_data,\n",
    "        \"y_data\": y_data,\n",
    "        \"y_err_stat\": y_err_stat,\n",
    "        \"y_err_sys\": y_err_sys,\n",
    "        \"x_sep_data\": x_sep_data,\n",
    "        \"y_sep_data\": y_sep_data,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_covmat(data_dict):\n",
    "    covmat_tr = np.zeros((data_dict[\"y_tr\"].shape[0], data_dict[\"y_tr\"].shape[0]))\n",
    "    for i in range(data_dict[\"y_tr\"].shape[0]):\n",
    "        for j in range(data_dict[\"y_tr\"].shape[0]):\n",
    "            covmat_tr[i, j] = (\n",
    "                data_dict[\"y_tr_err_sys\"][i] * data_dict[\"y_tr_err_sys\"][j]\n",
    "                + data_dict[\"y_tr\"][i] * data_dict[\"y_tr\"][j]\n",
    "            )\n",
    "            if i == j:\n",
    "                covmat_tr[i, j] += data_dict[\"y_tr_err_stat\"][i] ** 2\n",
    "                \n",
    "    covmat_val = np.zeros((data_dict[\"y_val\"].shape[0], data_dict[\"y_val\"].shape[0]))\n",
    "    for i in range(data_dict[\"y_val\"].shape[0]):\n",
    "        for j in range(data_dict[\"y_val\"].shape[0]):\n",
    "            covmat_val[i, j] = (\n",
    "                data_dict[\"y_val_err_sys\"][i] * data_dict[\"y_val_err_sys\"][j]\n",
    "                + data_dict[\"y_val\"][i] * data_dict[\"y_val\"][j]\n",
    "            )\n",
    "            if i == j:\n",
    "                covmat_val[i, j] += data_dict[\"y_val_err_stat\"][i] ** 2\n",
    "    \n",
    "    return {\"tr\": covmat_tr, \"val\": covmat_val}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chi2_with_covmat(covmat, ndata):\n",
    "    inverted_tr = np.linalg.inv(covmat[\"tr\"])\n",
    "    inverted_val = np.linalg.inv(covmat[\"val\"])\n",
    "    ndata_tr = ndata[\"tr\"]\n",
    "    ndata_val = ndata[\"val\"]\n",
    "    # Convert numpy array into tensorflow object\n",
    "    invcovmat_tr = K.constant(inverted_tr)\n",
    "    invcovmat_val = K.constant(inverted_val)\n",
    "\n",
    "    def custom_loss(y_true, y_pred):\n",
    "        # (yt - yp) * covmat * (yt - yp)\n",
    "        tmp = y_true - y_pred\n",
    "        import pdb; pdb.set_trace()\n",
    "        try:\n",
    "            right_dot = tf.tensordot(invcovmat_tr, K.transpose(tmp), axes=1)\n",
    "        except:\n",
    "            pass\n",
    "        else:\n",
    "            return tf.tensordot(tmp, right_dot, axes=1) / ndata_tr\n",
    "        \n",
    "        right_dot = tf.tensordot(invcovmat_val, K.transpose(tmp), axes=1)\n",
    "        return tf.tensordot(tmp, right_dot, axes=1) / ndata_val\n",
    "\n",
    "    return custom_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_trainer(data_dict, runcard, **hyperparameters):\n",
    "    # Collect the values for the hyperparameters\n",
    "    optimizer = hyperparameters.get(\"optimizer\", \"adam\")\n",
    "    activation = hyperparameters.get(\"activation\", \"relu\")\n",
    "    epochs = hyperparameters.get(\"epochs\", 10)\n",
    "    nb_layers = hyperparameters.get(\"nb_layers\", (2, {'units_layer_1_2': 64, 'units_layer_2_2': 32}))\n",
    "    \n",
    "    layers = list(nb_layers[1].keys())\n",
    "    nb_units_1 = nb_layers[1][layers[0]]\n",
    "\n",
    "    # Construct the model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(units=nb_units_1, activation=activation, input_shape=[2]))\n",
    "    \n",
    "    if nb_layers[0] > 1:\n",
    "        for layer in layers[1:]:\n",
    "            model.add(Dense(units=nb_layers[1][layer], activation=activation))\n",
    "    \n",
    "    # output layer\n",
    "    model.add(Dense(units=1, activation=\"linear\"))\n",
    "\n",
    "    # Compile the Model as usual\n",
    "    ndata = {\"tr\": data_dict[\"y_tr\"].shape[0], \"val\": data_dict[\"y_val\"].shape[0]}\n",
    "    covmat = compute_covmat(data_dict)\n",
    "    #model.compile(loss=chi2_with_covmat(covmat, ndata), optimizer=optimizer, metrics=[\"accuracy\"])\n",
    "    model.compile(loss=\"mse\", optimizer=optimizer, metrics=[\"accuracy\"])\n",
    "\n",
    "    # Callbacks for Early Stopping\n",
    "    ES = EarlyStopping(\n",
    "        monitor=\"val_loss\",\n",
    "        mode=\"min\",\n",
    "        verbose=0,\n",
    "        patience=10,\n",
    "        restore_best_weights=True,\n",
    "    )\n",
    "\n",
    "    # Fit the Model as usual\n",
    "    model.fit(\n",
    "        data_dict[\"x_tr\"],\n",
    "        data_dict[\"y_tr\"],\n",
    "        validation_data=(data_dict[\"x_val\"], data_dict[\"y_val\"]),\n",
    "        epochs=epochs,\n",
    "        verbose=0,\n",
    "        callbacks=[ES],\n",
    "    )\n",
    "\n",
    "    # Evaluate the Model on the test. Note that this will be the\n",
    "    # parameter to hyperoptimize. If one wants, one could use x/y_tr.\n",
    "    # This might be ideal if one have very small number of datapoints\n",
    "    scores = model.evaluate(data_dict[\"x_val\"], data_dict[\"y_val\"], verbose=0)\n",
    "    # Return the value of the validation loss\n",
    "    return model, scores[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_layers_dict(runcard):\n",
    "    layers_list = []\n",
    "    nb_units_per_layer = runcard[\"nb_units_per_layer\"]\n",
    "    for n in runcard[\"layers_choices\"]:\n",
    "        layer_dict = {}\n",
    "        for i in range(1, n+1):\n",
    "            key = f\"units_layer_{i}_{n}\"\n",
    "            layer_dict[f\"units_layer_{i}\"] = hp.quniform(key, nb_units_per_layer[\"min\"], nb_units_per_layer[\"max\"], nb_units_per_layer[\"samples\"])\n",
    "        layers_list.append((n, layer_dict))\n",
    "    return hp.choice(\"nb_layers\", layers_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_hyperspace(runcard):\n",
    "    learning_rate_choices = runcard[\"learning_rate_choices\"]\n",
    "    activation = hp.choice(\"activation\", runcard[\"activation_choices\"])\n",
    "    optimizer = hp.choice(\"optimizer\", runcard[\"optimizer_choices\"])\n",
    "    epochs = hp.choice(\"epochs\", runcard[\"epochs_choices\"])\n",
    "    initializer = hp.choice(\"initializer\", runcard[\"initializer_choices\"])\n",
    "    learning_rate = hp.loguniform(\"learning_rate\", float(learning_rate_choices[\"min\"]), float(learning_rate_choices[\"max\"]))\n",
    "    nb_layers = construct_layers_dict(runcard)\n",
    "    \n",
    "    return {\n",
    "        \"activation\": activation,\n",
    "        \"optimizer\": optimizer,\n",
    "        \"epochs\": epochs,\n",
    "        \"initializer\": initializer,\n",
    "        \"learning_rate\": learning_rate,\n",
    "        \"nb_layers\": nb_layers\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_hyperopt(data_dict, runcard):\n",
    "    hyperspace = define_hyperspace(runcard)\n",
    "\n",
    "    # Define the hyperoptimization function\n",
    "    def hyper_function(hyperspace_dict):\n",
    "        _, val_loss = model_trainer(data_dict, runcard, **hyperspace_dict)\n",
    "        return {\"loss\": val_loss, \"status\": \"ok\"}\n",
    "\n",
    "    trials = FileTrials(hyperopt_path, parameters=hyperspace)\n",
    "    best = fmin(\n",
    "        fn=hyper_function,\n",
    "        space=hyperspace,\n",
    "        verbose=1,\n",
    "        max_evals=runcard[\"nb_trials\"],\n",
    "        algo=tpe.suggest,\n",
    "        trials=trials,\n",
    "    )\n",
    "    # Save the best hyperparameters combination in order to return it later\n",
    "    best_setup = space_eval(hyperspace, best)\n",
    "    # Write the output of the best into a file\n",
    "    with open(f\"{hyperopt_path}/best_hyperparameters.yaml\", \"w\") as file:\n",
    "        yaml.dump(best_setup, file, default_flow_style=False)\n",
    "    # Write the all the history of the hyperopt into a file\n",
    "    with open(f\"{hyperopt_path}/hyperopt_history.pickle\", \"wb\") as histfile:\n",
    "        pickle.dump(trials.trials, histfile)\n",
    "    return best_setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_constant_x(best_model, data_dict):\n",
    "    # loop over x values\n",
    "    for i in range(len(data_dict[\"x_sep_data\"])):\n",
    "        x = data_dict[\"x_sep_data\"][i]\n",
    "        y = data_dict[\"y_sep_data\"][i]\n",
    "        x_grid = np.linspace(x[0], x[-1], 100)\n",
    "        y_pred = best_model(x_grid)\n",
    "        \n",
    "        fig, ax = plt.subplots(1, 1) \n",
    "        ax.plot(x_grid[:, 1], y_pred, color=\"red\", label=\"Prediction\")\n",
    "        ax.scatter(x[:, 1], y, color=\"blue\", label=\"Data\")\n",
    "        ax.legend()\n",
    "        ax.set_xlabel(\"$Q^2$ [GeV$^2$]\")\n",
    "        ax.set_ylabel(\"$F_2$\")\n",
    "        ax.set_title(f\"Prediction of $F_2$ at $x={x[0,0]}$\")\n",
    "        plt.show()\n",
    "        plt.savefig(f\"{fits_path}/FIT_{x[0,0]}.png\")\n",
    "        ax.clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runcard = load_runcard(\"runcard.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict = load_data(runcard)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = perform_hyperopt(data_dict, runcard)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model,_ = model_trainer(data_dict, runcard, **best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_constant_x(best_model, data_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ADD Inputs runcard:\n",
    "\n",
    "Add hyperopt nb layers\n",
    "\n",
    "Seperate scripts:\n",
    "- hyperopt (combine with filetrials?)\n",
    "- training (option replicas)\n",
    "- plotting\n",
    "\n",
    "filetrials.py:\n",
    "- change path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "51b07192feadff41234e4986821c542e33f28bd852adab907add648296a24759"
  },
  "kernelspec": {
   "display_name": "nnpdf40",
   "language": "python",
   "name": "nnpdf40"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
