{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import yaml\n",
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "from pathlib import Path\n",
    "from filetrials import FileTrials, space_eval\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.callbacks import Callback, EarlyStopping\n",
    "\n",
    "# Import hyperopt modules\n",
    "from hyperopt import hp, fmin, tpe\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix the seeds for reproducible results\n",
    "tf.random.set_seed(1234)\n",
    "np.random.seed(5678)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_trval(x_data, y_data, perc = 0.3):\n",
    "    size_val = round(x_data.shape[0]*perc)\n",
    "    if size_val > 0:\n",
    "        idx = np.random.choice(np.arange(1, x_data.shape[0]-1, 2), size_val, replace=False)\n",
    "        x_val = x_data[idx]\n",
    "        y_val = y_data[idx]\n",
    "        x_tr = np.delete(x_data, idx, axis = 0)\n",
    "        y_tr = np.delete(y_data, idx)\n",
    "    else:\n",
    "        x_tr = x_data\n",
    "        y_tr = y_data\n",
    "        x_val = None\n",
    "        y_val = None\n",
    "    return x_tr, y_tr, x_val, y_val, size_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(Q2_cut=None): #Q2 cut does not work yet bc of empty x_val in concetanation\n",
    "    filenames = os.listdir(\"./data\")\n",
    "    # filenames = [\"DATA_CHORUS_0.02.yaml\"]\n",
    "    \n",
    "    x_all_data = []\n",
    "    y_all_data = []\n",
    "\n",
    "    for i, filename in enumerate(filenames):\n",
    "        with open(\"./data/\" + filename, \"r\") as file:\n",
    "            input_data = yaml.safe_load(file)\n",
    "\n",
    "        x = input_data[\"x\"]\n",
    "        Q2 = np.array(input_data[\"Q2\"])\n",
    "        F_2 = np.array(input_data[\"F_2\"])\n",
    "        \n",
    "        if Q2_cut != None:\n",
    "            Q2_mask = np.where(Q2<Q2_cut)\n",
    "            Q2 = Q2[Q2_mask]\n",
    "            F_2 = F_2[Q2_mask]\n",
    "\n",
    "        if i == 0:\n",
    "            x_data = np.zeros((len(Q2), 2))\n",
    "            x_data[:, 0] = x\n",
    "            x_data[:, 1] = Q2 \n",
    "            y_data = F_2\n",
    "            x_all_data.append(x_data)\n",
    "            y_all_data.append(y_data)\n",
    "            x_tr, y_tr, x_val, y_val, size_val = split_trval(x_data, y_data)\n",
    "        else:\n",
    "            x_data = np.zeros((len(Q2), 2))\n",
    "            x_data[:, 0] = x\n",
    "            x_data[:, 1] = Q2 \n",
    "            y_data = F_2\n",
    "            x_all_data.append(x_data)\n",
    "            y_all_data.append(y_data)\n",
    "            x_tr_new, y_tr_new, x_val_new, y_val_new, size_val = split_trval(x_data, y_data)\n",
    "\n",
    "            x_tr = np.concatenate([x_tr, x_tr_new], axis = 0)\n",
    "            y_tr = np.concatenate([y_tr, y_tr_new], axis = 0)\n",
    "            if size_val > 0:\n",
    "                x_val = np.concatenate([x_val, x_val_new], axis = 0)\n",
    "                y_val = np.concatenate([y_val, y_val_new], axis = 0)\n",
    "                \n",
    "    return x_tr, y_tr, x_val, y_val, x_all_data, y_all_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_tr, y_tr, x_val, y_val, x_data, y_data = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.9102, 0.9363, 0.9116, 1.1789, 1.0323, 1.0695, 0.3779, 0.4363,\n",
       "       1.1908, 1.3983, 0.2015, 0.2484, 1.2995, 1.3028, 1.3039, 1.4266,\n",
       "       1.1504, 1.1984, 0.0863, 0.1244, 0.711 , 0.6338])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_trainer(**hyperparameters):\n",
    "    # Collect the values for the hyperparameters\n",
    "    optimizer = hyperparameters.get(\"optimizer\", \"adam\")\n",
    "    activation = hyperparameters.get(\"activation\", 'relu')\n",
    "    epochs = hyperparameters.get(\"epochs\", 10)\n",
    "    nb_units_layer_1 = hyperparameters.get(\"units_1\", 64)\n",
    "    nb_units_layer_2 = hyperparameters.get(\"units_2\", 32)\n",
    "    \n",
    "    # Construct the model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(units=nb_units_layer_1, activation=activation, input_shape=[2]))\n",
    "    model.add(Dense(units=nb_units_layer_2, activation=activation))\n",
    "    model.add(Dense(units= 1, activation = 'linear'))\n",
    "    \n",
    "    # Compile the Model as usual\n",
    "    model.compile(loss='mse', optimizer=optimizer, metrics=['accuracy'])\n",
    "    \n",
    "    # Callbacks for Early Stopping\n",
    "    ES = EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        mode='min',\n",
    "        verbose=0,\n",
    "        patience=10,\n",
    "        restore_best_weights=True\n",
    "    )\n",
    "    \n",
    "    # Fit the Model as usual\n",
    "    model.fit(\n",
    "        x_tr, \n",
    "        y_tr, \n",
    "        validation_data=(x_val ,y_val), \n",
    "        epochs=epochs, \n",
    "        batch_size=1, \n",
    "        verbose=0, \n",
    "        callbacks=[ES]\n",
    "    )\n",
    "    \n",
    "    # Evaluate the Model on the test. Note that this will be the\n",
    "    # parameter to hyperoptimize. If one wants, one could use x/y_tr.\n",
    "    # This might be ideal if one have very small number of datapoints\n",
    "    scores = model.evaluate(x_val, y_val, verbose=0)\n",
    "    # Return the value of the validation loss\n",
    "    return model, scores[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let us now define the hyperparameter space\n",
    "epochs_choices = [2000, 5000]\n",
    "activation_choices = [\"sigmoid\", \"tanh\"]\n",
    "optimizer_choices = [\"adam\", \"RMSprop\", \"nadam\"]\n",
    "initializer_choices = [\"random_normal\", \"random_uniform\", \"glorot_normal\", \"glorot_uniform\"]\n",
    "\n",
    "nb_units_layer_1 = hp.quniform(\"units_1\", 10, 50, 4)\n",
    "nb_units_layer_2 = hp.quniform(\"units_2\", 5, 50, 4)\n",
    "activation = hp.choice(\"activation\", activation_choices)\n",
    "optimizer = hp.choice(\"optimizer\", optimizer_choices)\n",
    "epochs = hp.choice(\"epochs\", epochs_choices)\n",
    "# initializer = hp.choice(\"initializer\", initializer_choices)\n",
    "#learning_rate = \n",
    "\n",
    "hyperspace = {\n",
    "    \"units_1\": nb_units_layer_1,\n",
    "    \"units_2\": nb_units_layer_2,\n",
    "    \"activation\": activation,\n",
    "    \"optimizer\": optimizer,\n",
    "    \"epochs\": epochs\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the hyperoptimization function\n",
    "def hyper_function(hyperspace_dict):\n",
    "    _, val_loss = model_trainer(**hyperspace_dict)\n",
    "    return {\"loss\": val_loss, \"status\": \"ok\"}\n",
    "\n",
    "def perform_hyperopt(hyper_space, folder_path, nb_trials=2):\n",
    "    trials = FileTrials(folder_path, parameters=hyper_space)\n",
    "    best = fmin(fn=hyper_function, space=hyperspace, verbose=1, max_evals=nb_trials, algo=tpe.suggest, trials=trials)\n",
    "    # Save the best hyperparameters combination in order to return it later\n",
    "    best_setup = space_eval(hyper_space, best)\n",
    "    # Write the output of the best into a file\n",
    "    with open(f\"{folder_path}/best_hyperparameters.yaml\", \"w\") as file:\n",
    "        yaml.dump(best_setup, file, default_flow_style=False)\n",
    "    # Write the all the history of the hyperopt into a file\n",
    "    with open(f\"{folder_path}/hyperopt_history.pickle\", \"wb\") as histfile:\n",
    "        pickle.dump(trials.trials, histfile)\n",
    "    return best_setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                                                                                                     | 0/500 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-22 14:28:45.506603: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-04-22 14:28:45.684703: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 26%|███████████████████████████████████████████████████████▍                                                                                                                                                             | 130/500 [33:06<1:23:03, 13.47s/trial, best loss: 0.000923982122913003]"
     ]
    }
   ],
   "source": [
    "current_path = Path().absolute()\n",
    "best_params = perform_hyperopt(hyperspace, current_path, nb_trials=500)\n",
    "best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, we can generate Predictions\n",
    "y_tr_pred = best_model.predict(x_tr)\n",
    "y_val_pred = best_model.predict(x_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(x_tr[:,1], y_tr, label = \"Training Data\")\n",
    "plt.scatter(x_tr[:,1], y_tr_pred, color = \"red\", label = \"Training Prediction\")\n",
    "plt.scatter(x_val[:,1], y_val, label = \" Validation Data\")\n",
    "plt.scatter(x_val[:,1], y_val_pred, color = \"green\", label = \"Validation Prediction\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_constant_x(model, x_data, y_data):\n",
    "    for i, x in enumerate(x_data):\n",
    "        y = y_data[i]\n",
    "        x_grid = np.linspace(x[0], x[-1], 100)\n",
    "        y_pred = model(x_grid)\n",
    "        #import pdb; pdb.set_trace()\n",
    "        plt.plot(x_grid[:,1], y_pred, color=\"red\", label=\"Prediction\")\n",
    "        plt.scatter(x[:,1], y, color=\"blue\", label=\"Data\")\n",
    "        plt.legend()\n",
    "        plt.xlabel(\"$Q^2$ [GeV$^2$]\")\n",
    "        plt.ylabel(\"$F_2$\")\n",
    "        plt.title(f\"Prediction of $F_2$ at $x={x[0,0]}$\")\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_constant_x(best_model, x_data, y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "51b07192feadff41234e4986821c542e33f28bd852adab907add648296a24759"
  },
  "kernelspec": {
   "display_name": "nnpdf40",
   "language": "python",
   "name": "nnpdf40"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
