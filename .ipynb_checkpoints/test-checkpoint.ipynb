{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import yaml\n",
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.backend as K\n",
    "import hyperopt\n",
    "\n",
    "from pathlib import Path\n",
    "from filetrials import FileTrials, space_eval\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.callbacks import Callback, EarlyStopping\n",
    "\n",
    "# Import hyperopt modules\n",
    "from hyperopt import hp, fmin, tpe\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix the seeds for reproducible results\n",
    "tf.random.set_seed(1234)\n",
    "np.random.seed(5678)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_path = Path().absolute()\n",
    "hyperopt_path = current_path / \"hyperopt\"\n",
    "hyperopt_path.mkdir(exist_ok=True)\n",
    "fits_path = current_path / \"fits\"\n",
    "fits_path.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load runcard with parameters\n",
    "def load_runcard(filename):\n",
    "    with open(f\"{current_path}/\" + filename, \"r\") as file:\n",
    "        input_params = yaml.safe_load(file)\n",
    "    return input_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_trval(x_data, y_data, perc = 0.3):\n",
    "    size_val = round(x_data.shape[0]*perc)\n",
    "    idx = np.random.choice(np.arange(1, x_data.shape[0]-1, 2), size_val, replace=False)\n",
    "    x_val = x_data[idx]\n",
    "    y_val = y_data[idx]\n",
    "    x_tr = np.delete(x_data, idx, axis = 0)\n",
    "    y_tr = np.delete(y_data, idx)\n",
    "    return x_tr, y_tr, x_val, y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(runcard):\n",
    "    filenames = os.listdir(f\"{current_path}/data\")\n",
    "\n",
    "    x_sep_data = []\n",
    "    y_sep_data = []\n",
    "\n",
    "    for i, filename in enumerate(filenames):\n",
    "        with open(f\"{current_path}/data/\" + filename, \"r\") as file:\n",
    "            input_data = yaml.safe_load(file)\n",
    "\n",
    "        x = input_data[\"x\"]\n",
    "        Q2 = np.array(input_data[\"Q2\"])\n",
    "        F_2 = np.array(input_data[\"F_2\"])\n",
    "        F_2_err_stat = np.array(input_data[\"F_2_err_stat\"])\n",
    "        F_2_err_sys = np.array(input_data[\"F_2_err_sys\"])\n",
    "\n",
    "        if runcard[\"Q2_cut\"] != None:\n",
    "            Q2_mask = np.where(Q2 < runcard[\"Q2_cut\"])\n",
    "            Q2 = Q2[Q2_mask]\n",
    "            F_2 = F_2[Q2_mask]\n",
    "            F_2_err_stat = F_2_err_stat[Q2_mask]\n",
    "            F_2_err_sys = F_2_err_sys[Q2_mask]\n",
    "\n",
    "        if i == 0:\n",
    "            x_data = np.zeros((len(Q2), 2))\n",
    "            x_data[:, 0] = x\n",
    "            x_data[:, 1] = Q2\n",
    "            y_data = F_2\n",
    "            x_sep_data.append(x_data)\n",
    "            y_sep_data.append(y_data)\n",
    "            y_err_stat = F_2_err_stat\n",
    "            y_err_sys = F_2_err_sys\n",
    "            \n",
    "            if x_data.shape[0] >= 3:\n",
    "                x_tr, y_tr, x_val, y_val = split_trval(x_data, y_data, perc=runcard[\"validation_size\"])\n",
    "                val = True\n",
    "            else:\n",
    "                x_tr = x_data\n",
    "                y_tr = y_data\n",
    "                val = False\n",
    "        else:\n",
    "            x_data_new = np.zeros((len(Q2), 2))\n",
    "            x_data_new[:, 0] = x\n",
    "            x_data_new[:, 1] = Q2\n",
    "            y_data_new = F_2\n",
    "            y_err_stat_new = F_2_err_stat\n",
    "            y_err_sys_new = F_2_err_sys\n",
    "            \n",
    "            \n",
    "            if x_data_new.shape[0] >= 3:\n",
    "                x_tr_new, y_tr_new, x_val_new, y_val_new = split_trval(\n",
    "                    x_data_new, y_data_new, perc=runcard[\"validation_size\"]\n",
    "                )\n",
    "                if val:\n",
    "                    x_val = np.concatenate([x_val, x_val_new], axis=0)\n",
    "                    y_val = np.concatenate([y_val, y_val_new], axis=0)\n",
    "                else:\n",
    "                    x_val = x_val_new\n",
    "                    y_val = y_val_new\n",
    "                    val = True\n",
    "                \n",
    "            else:\n",
    "                x_tr_new = x_data_new\n",
    "                y_tr_new = y_data_new\n",
    "\n",
    "            x_tr = np.concatenate([x_tr, x_tr_new], axis=0)\n",
    "            y_tr = np.concatenate([y_tr, y_tr_new], axis=0)\n",
    "            y_err_stat = np.concatenate([y_err_stat, y_err_stat_new], axis=0)\n",
    "            y_err_sys = np.concatenate([y_err_sys, y_err_sys_new], axis=0)\n",
    "            \n",
    "            x_sep_data.append(x_data_new)\n",
    "            y_sep_data.append(y_data_new)\n",
    "            x_data = np.concatenate([x_data, x_data_new], axis=0)\n",
    "            y_data = np.concatenate([y_data, y_data_new], axis=0)\n",
    "\n",
    "    return {\n",
    "        \"x_tr\": x_tr,\n",
    "        \"y_tr\": y_tr,\n",
    "        \"x_val\": x_val,\n",
    "        \"y_val\": y_val,\n",
    "        \"x_data\": x_data,\n",
    "        \"y_data\": y_data,\n",
    "        \"y_err_stat\": y_err_stat,\n",
    "        \"y_err_sys\": y_err_sys,\n",
    "        \"x_sep_data\": x_sep_data,\n",
    "        \"y_sep_data\": y_sep_data,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_covmat(data_dict):\n",
    "    covmat = np.zeros((data_dict[\"y_data\"].shape[0], data_dict[\"y_data\"].shape[0]))\n",
    "    for i in range(data_dict[\"y_data\"].shape[0]):\n",
    "        for j in range(data_dict[\"y_data\"].shape[0]):\n",
    "            covmat[i, j] = (\n",
    "                data_dict[\"y_err_sys\"][i] * data_dict[\"y_err_sys\"][j]\n",
    "                + data_dict[\"y_data\"][i] * data_dict[\"y_data\"][j]\n",
    "            )\n",
    "            if i == j:\n",
    "                covmat[i, j] += data_dict[\"y_err_stat\"][i] ** 2\n",
    "    return covmat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chi2_with_covmat(covmat, ndata):\n",
    "    inverted = np.linalg.inv(covmat)\n",
    "    # Convert numpy array into tensorflow object\n",
    "    invcovmat = K.constant(inverted)\n",
    "\n",
    "    def custom_loss(y_true, y_pred):\n",
    "        # (yt - yp) * covmat * (yt - yp)\n",
    "        tmp = y_true - y_pred\n",
    "        import pdb;pdb.set_trace()\n",
    "        right_dot = tf.tensordot(invcovmat, K.transpose(tmp), axes=1)\n",
    "        return tf.tensordot(tmp, right_dot, axes=1) / ndata\n",
    "\n",
    "    return custom_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_trainer(data_dict, runcard, **hyperparameters):\n",
    "    # Collect the values for the hyperparameters\n",
    "    nb_units_layer_1 = hyperparameters.get(\"units_1\", 64)\n",
    "    nb_units_layer_2 = hyperparameters.get(\"units_2\", 32)\n",
    "    optimizer = hyperparameters.get(\"optimizer\", \"adam\")\n",
    "    activation = hyperparameters.get(\"activation\", \"relu\")\n",
    "    epochs = hyperparameters.get(\"epochs\", 10)\n",
    "    nb_layers = hyperparameters.get(\"nb_layers\", (2, {'units_layer_1': units_layer_1, 'units_layer_2': units_layer_2}))\n",
    "    \n",
    "    nb_units_1 = nb_layers[1][\"units_layer_1\"]\n",
    "\n",
    "    # Construct the model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(units=nb_units_1, activation=activation, input_shape=[2]))\n",
    "    \n",
    "    if nb_layers[0] > 1:\n",
    "        for layer in list(nb_layers[1].keys())[1:]:\n",
    "            model.add(Dense(units=nb_layers[1][layer], activation=activation))\n",
    "    \n",
    "    # output layer\n",
    "    model.add(Dense(units=1, activation=\"linear\"))\n",
    "\n",
    "    # Compile the Model as usual\n",
    "    ndata = data_dict[\"y_tr\"].shape[0]\n",
    "    covmat = compute_covmat(data_dict)\n",
    "    #model.compile(loss=chi2_with_covmat(covmat, ndata), optimizer=optimizer, metrics=[\"accuracy\"])\n",
    "    model.compile(loss=\"mse\", optimizer=optimizer, metrics=[\"accuracy\"])\n",
    "\n",
    "    # Callbacks for Early Stopping\n",
    "    ES = EarlyStopping(\n",
    "        monitor=\"val_loss\",\n",
    "        mode=\"min\",\n",
    "        verbose=0,\n",
    "        patience=10,\n",
    "        restore_best_weights=True,\n",
    "    )\n",
    "\n",
    "    # Fit the Model as usual\n",
    "    model.fit(\n",
    "        data_dict[\"x_tr\"],\n",
    "        data_dict[\"y_tr\"],\n",
    "        validation_data=(data_dict[\"x_val\"], data_dict[\"y_val\"]),\n",
    "        epochs=epochs,\n",
    "        batch_size=runcard[\"batch_size\"],\n",
    "        verbose=0,\n",
    "        callbacks=[ES],\n",
    "    )\n",
    "\n",
    "    # Evaluate the Model on the test. Note that this will be the\n",
    "    # parameter to hyperoptimize. If one wants, one could use x/y_tr.\n",
    "    # This might be ideal if one have very small number of datapoints\n",
    "    scores = model.evaluate(data_dict[\"x_val\"], data_dict[\"y_val\"], verbose=0)\n",
    "    # Return the value of the validation loss\n",
    "    return model, scores[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_hyperspace(runcard):\n",
    "    nb_units_layer_1_choices = runcard[\"nb_units_layer_1_choices\"]\n",
    "    nb_units_layer_2_choices = runcard[\"nb_units_layer_2_choices\"]\n",
    "    learning_rate_choices = runcard[\"learning_rate_choices\"]\n",
    "\n",
    "    nb_units_layer_1 = hp.quniform(\"units_1\", nb_units_layer_1_choices[\"min\"], nb_units_layer_1_choices[\"max\"], nb_units_layer_1_choices[\"samples\"])\n",
    "    nb_units_layer_2 = hp.quniform(\"units_2\", nb_units_layer_2_choices[\"min\"], nb_units_layer_2_choices[\"max\"], nb_units_layer_2_choices[\"samples\"])\n",
    "    activation = hp.choice(\"activation\", runcard[\"activation_choices\"])\n",
    "    optimizer = hp.choice(\"optimizer\", runcard[\"optimizer_choices\"])\n",
    "    epochs = hp.choice(\"epochs\", runcard[\"epochs_choices\"])\n",
    "    initializer = hp.choice(\"initializer\", runcard[\"initializer_choices\"])\n",
    "    learning_rate = hp.loguniform(\"learning_rate\", float(learning_rate_choices[\"min\"]), float(learning_rate_choices[\"max\"]))\n",
    "    nb_layers = hp.choice(\"nb_layers\",\n",
    "                      [\n",
    "                          (\n",
    "                              1, {\n",
    "                                  \"units_layer_1\": hp.quniform(\"units_layer_1\", 10, 50, 4)\n",
    "                                  }\n",
    "                          ),\n",
    "                          (\n",
    "                              2, {\n",
    "                                  \"units_layer_1\": hp.quniform(\"units_layer_1\", 10, 50, 4), \n",
    "                                  \"units_layer_2\": hp.quniform(\"units_layer_2\", 10, 50, 4)\n",
    "                                  }\n",
    "                          )\n",
    "                      ])\n",
    "    \n",
    "    return {\n",
    "        \"units_1\": nb_units_layer_1,\n",
    "        \"units_2\": nb_units_layer_2,\n",
    "        \"activation\": activation,\n",
    "        \"optimizer\": optimizer,\n",
    "        \"epochs\": epochs,\n",
    "        \"initializer\": initializer,\n",
    "        \"learning_rate\": learning_rate,\n",
    "        \"nb_layers\": nb_layers\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, {'units_layer_1': 36.0})"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hyperspace = define_hyperspace(runcard)\n",
    "nb_layers = hyperopt.pyll.stochastic.sample(hyperspace)[\"nb_layers\"]\n",
    "nb_layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['units_layer_2']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(nb_layers[1].keys())[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "ename": "DuplicateLabel",
     "evalue": "units_layer_1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mDuplicateLabel\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_3692/1671200262.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mbest_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mperform_hyperopt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mruncard\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_3692/290507074.py\u001b[0m in \u001b[0;36mperform_hyperopt\u001b[0;34m(data_dict, runcard)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mtrials\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFileTrials\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhyperopt_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhyperspace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     best = fmin(\n\u001b[0m\u001b[1;32m     11\u001b[0m         \u001b[0mfn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhyper_function\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mspace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhyperspace\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/nnpdf40/lib/python3.9/site-packages/hyperopt/fmin.py\u001b[0m in \u001b[0;36mfmin\u001b[0;34m(fn, space, algo, max_evals, timeout, loss_threshold, trials, rstate, allow_trials_fmin, pass_expr_memo_ctrl, catch_eval_exceptions, verbose, return_argmin, points_to_evaluate, max_queue_len, show_progressbar, early_stop_fn, trials_save_file)\u001b[0m\n\u001b[1;32m    505\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mallow_trials_fmin\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrials\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"fmin\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 507\u001b[0;31m         return trials.fmin(\n\u001b[0m\u001b[1;32m    508\u001b[0m             \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    509\u001b[0m             \u001b[0mspace\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/nnpdf40/lib/python3.9/site-packages/hyperopt/base.py\u001b[0m in \u001b[0;36mfmin\u001b[0;34m(self, fn, space, algo, max_evals, timeout, loss_threshold, max_queue_len, rstate, verbose, pass_expr_memo_ctrl, catch_eval_exceptions, return_argmin, show_progressbar, early_stop_fn, trials_save_file)\u001b[0m\n\u001b[1;32m    680\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mfmin\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfmin\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    681\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 682\u001b[0;31m         return fmin(\n\u001b[0m\u001b[1;32m    683\u001b[0m             \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    684\u001b[0m             \u001b[0mspace\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/nnpdf40/lib/python3.9/site-packages/hyperopt/fmin.py\u001b[0m in \u001b[0;36mfmin\u001b[0;34m(fn, space, algo, max_evals, timeout, loss_threshold, trials, rstate, allow_trials_fmin, pass_expr_memo_ctrl, catch_eval_exceptions, verbose, return_argmin, points_to_evaluate, max_queue_len, show_progressbar, early_stop_fn, trials_save_file)\u001b[0m\n\u001b[1;32m    532\u001b[0m             \u001b[0mtrials\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_trials_to_calculate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpoints_to_evaluate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 534\u001b[0;31m     \u001b[0mdomain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbase\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDomain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mspace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpass_expr_memo_ctrl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpass_expr_memo_ctrl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    535\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    536\u001b[0m     rval = FMinIter(\n",
      "\u001b[0;32m~/anaconda3/envs/nnpdf40/lib/python3.9/site-packages/hyperopt/base.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, fn, expr, workdir, pass_expr_memo_ctrl, name, loss_target)\u001b[0m\n\u001b[1;32m    840\u001b[0m                 \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"label\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    841\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 842\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mDuplicateLabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    843\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"obj\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    844\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mDuplicateLabel\u001b[0m: units_layer_1"
     ]
    }
   ],
   "source": [
    "best_params = perform_hyperopt(data_dict, runcard)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_layers = hp.choice(\"nb_layers\",\n",
    "                      [\n",
    "                          (\n",
    "                              1, {\n",
    "                                  \"units_layer_1\": hp.quniform(\"units_layer_1\", 10, 50, 4)\n",
    "                                  }\n",
    "                          ),\n",
    "                          (\n",
    "                              2, {\n",
    "                                  \"units_layer_1\": hp.quniform(\"units_layer_1\", 10, 50, 4), \n",
    "                                  \"units_layer_2\": hp.quniform(\"units_layer_2\", 10, 50, 4)\n",
    "                                  }\n",
    "                          )\n",
    "                      ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_hyperopt(data_dict, runcard):\n",
    "    hyperspace = define_hyperspace(runcard)\n",
    "\n",
    "    # Define the hyperoptimization function\n",
    "    def hyper_function(hyperspace_dict):\n",
    "        _, val_loss = model_trainer(data_dict, runcard, **hyperspace_dict)\n",
    "        return {\"loss\": val_loss, \"status\": \"ok\"}\n",
    "\n",
    "    trials = FileTrials(hyperopt_path, parameters=hyperspace)\n",
    "    best = fmin(\n",
    "        fn=hyper_function,\n",
    "        space=hyperspace,\n",
    "        verbose=1,\n",
    "        max_evals=runcard[\"nb_trials\"],\n",
    "        algo=tpe.suggest,\n",
    "        trials=trials,\n",
    "    )\n",
    "    # Save the best hyperparameters combination in order to return it later\n",
    "    best_setup = space_eval(hyperspace, best)\n",
    "    # Write the output of the best into a file\n",
    "    with open(f\"{hyperopt_path}/best_hyperparameters.yaml\", \"w\") as file:\n",
    "        yaml.dump(best_setup, file, default_flow_style=False)\n",
    "    # Write the all the history of the hyperopt into a file\n",
    "    with open(f\"{hyperopt_path}/hyperopt_history.pickle\", \"wb\") as histfile:\n",
    "        pickle.dump(trials.trials, histfile)\n",
    "    return best_setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_constant_x(best_model, data_dict):\n",
    "    # loop over x values\n",
    "    for i in range(len(data_dict[\"x_sep_data\"])):\n",
    "        x = data_dict[\"x_sep_data\"][i]\n",
    "        y = data_dict[\"y_sep_data\"][i]\n",
    "        x_grid = np.linspace(x[0], x[-1], 100)\n",
    "        y_pred = best_model(x_grid)\n",
    "        \n",
    "        fig, ax = plt.subplots(1, 1) \n",
    "        ax.plot(x_grid[:, 1], y_pred, color=\"red\", label=\"Prediction\")\n",
    "        ax.scatter(x[:, 1], y, color=\"blue\", label=\"Data\")\n",
    "        ax.legend()\n",
    "        ax.set_xlabel(\"$Q^2$ [GeV$^2$]\")\n",
    "        ax.set_ylabel(\"$F_2$\")\n",
    "        ax.set_title(f\"Prediction of $F_2$ at $x={x[0,0]}$\")\n",
    "        plt.show()\n",
    "        plt.savefig(f\"{fits_path}/FIT_{x[0,0]}.png\")\n",
    "        ax.clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "runcard = load_runcard(\"runcard.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict = load_data(runcard)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model,_ = model_trainer(data_dict, runcard, **best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_constant_x(best_model, data_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ADD Inputs runcard:\n",
    "\n",
    "Add hyperopt nb layers\n",
    "\n",
    "Seperate scripts:\n",
    "- hyperopt (combine with filetrials?)\n",
    "- training (option replicas)\n",
    "- plotting\n",
    "\n",
    "filetrials.py:\n",
    "- change path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "51b07192feadff41234e4986821c542e33f28bd852adab907add648296a24759"
  },
  "kernelspec": {
   "display_name": "nnpdf40",
   "language": "python",
   "name": "nnpdf40"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
