{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import yaml\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "from filetrials import FileTrials\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.callbacks import Callback, EarlyStopping\n",
    "\n",
    "# Import hyperopt modules\n",
    "from hyperopt import hp, fmin, tpe\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix the seeds for reproducible results\n",
    "tf.random.set_seed(1234)\n",
    "np.random.seed(5678)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_trval(x_data, y_data, perc = 0.3):\n",
    "    size_val = round(x_data.shape[0]*perc)\n",
    "    if size_val > 0:\n",
    "        idx = np.random.choice(np.arange(1, x_data.shape[0]-1, 2), size_val, replace=False)\n",
    "        x_val = x_data[idx]\n",
    "        y_val = y_data[idx]\n",
    "        x_tr = np.delete(x_data, idx, axis = 0)\n",
    "        y_tr = np.delete(y_data, idx)\n",
    "    else:\n",
    "        x_tr = x_data\n",
    "        y_tr = y_data\n",
    "        x_val = None\n",
    "        y_val = None\n",
    "    return x_tr, y_tr, x_val, y_val, size_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(Q2_cut=None): #Q2 cut does not work yet bc of empty x_val in concetanation\n",
    "    filenames = os.listdir(\"./data\")\n",
    "    # filenames = [\"DATA_CHORUS_0.02.yaml\"]\n",
    "    \n",
    "    x_all_data = []\n",
    "    y_all_data = []\n",
    "\n",
    "    for i, filename in enumerate(filenames):\n",
    "        with open(\"./data/\" + filename, \"r\") as file:\n",
    "            input_data = yaml.safe_load(file)\n",
    "\n",
    "        x = input_data[\"x\"]\n",
    "        Q2 = np.array(input_data[\"Q2\"])\n",
    "        F_2 = np.array(input_data[\"F_2\"])\n",
    "        \n",
    "        if Q2_cut != None:\n",
    "            Q2_mask = np.where(Q2<Q2_cut)\n",
    "            Q2 = Q2[Q2_mask]\n",
    "            F_2 = F_2[Q2_mask]\n",
    "\n",
    "        if i == 0:\n",
    "            x_data = np.zeros((len(Q2), 2))\n",
    "            x_data[:, 0] = x\n",
    "            x_data[:, 1] = Q2 \n",
    "            y_data = F_2\n",
    "            x_all_data.append(x_data)\n",
    "            y_all_data.append(y_data)\n",
    "            x_tr, y_tr, x_val, y_val, size_val = split_trval(x_data, y_data)\n",
    "        else:\n",
    "            x_data = np.zeros((len(Q2), 2))\n",
    "            x_data[:, 0] = x\n",
    "            x_data[:, 1] = Q2 \n",
    "            y_data = F_2\n",
    "            x_all_data.append(x_data)\n",
    "            y_all_data.append(y_data)\n",
    "            x_tr_new, y_tr_new, x_val_new, y_val_new, size_val = split_trval(x_data, y_data)\n",
    "\n",
    "            x_tr = np.concatenate([x_tr, x_tr_new], axis = 0)\n",
    "            y_tr = np.concatenate([y_tr, y_tr_new], axis = 0)\n",
    "            if size_val > 0:\n",
    "                x_val = np.concatenate([x_val, x_val_new], axis = 0)\n",
    "                y_val = np.concatenate([y_val, y_val_new], axis = 0)\n",
    "                \n",
    "    return x_tr, y_tr, x_val, y_val, x_all_data, y_all_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_tr, y_tr, x_val, y_val, x_data, y_data = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_trainer(**hyperparameters):\n",
    "    # Collect the values for the hyperparameters\n",
    "    nb_units_layer_1 = hyperparameters.get(\"units_1\", 64)\n",
    "    nb_units_layer_2 = hyperparameters.get(\"units_2\", 32)\n",
    "    optimizer = hyperparameters.get(\"optimizer\", \"adam\")\n",
    "    activation = hyperparameters.get(\"activation\", 'relu')\n",
    "    epochs = hyperparameters.get(\"epochs\", 10)\n",
    "    \n",
    "    # Construct the model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(units=nb_units_layer_1, activation=activation, input_shape=[2]))\n",
    "    model.add(Dense(units=nb_units_layer_2, activation=activation))\n",
    "    model.add(Dense(units= 1, activation = 'linear'))\n",
    "    \n",
    "    # Compile the Model as usual\n",
    "    model.compile(loss='mse', optimizer=optimizer, metrics=['accuracy'])\n",
    "    \n",
    "    # Callbacks for Early Stopping\n",
    "    ES = EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        mode='min',\n",
    "        verbose=0,\n",
    "        patience=10,\n",
    "        restore_best_weights=True\n",
    "    )\n",
    "    \n",
    "    # Fit the Model as usual\n",
    "    model.fit(\n",
    "        x_tr, \n",
    "        y_tr, \n",
    "        validation_data=(x_val ,y_val), \n",
    "        epochs=epochs, \n",
    "        batch_size=1, \n",
    "        verbose=0, \n",
    "        callbacks=[ES]\n",
    "    )\n",
    "    \n",
    "    # Evaluate the Model on the test. Note that this will be the\n",
    "    # parameter to hyperoptimize. If one wants, one could use x/y_tr.\n",
    "    # This might be ideal if one have very small number of datapoints\n",
    "    scores = model.evaluate(x_val, y_val, verbose=0)\n",
    "    # Return the value of the validation loss\n",
    "    return model, scores[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let us now define the hyperparameter space\n",
    "epochs_choices = [100, 1000, 2000]\n",
    "activation_choices = [\"relu\", \"sigmoid\", \"tanh\"]\n",
    "optimizer_choices = [\"adam\", \"Adadelta\", \"RMSprop\", \"nadam\"]\n",
    "initializer_choices = [\"random_normal\", \"random_uniform\", \"glorot_normal\", \"glorot_uniform\"]\n",
    "\n",
    "nb_units_layer_1 = hp.quniform(\"units_1\", 5, 25, 4)\n",
    "nb_units_layer_2 = hp.quniform(\"units_2\", 5, 25, 4)\n",
    "activation = hp.choice(\"activation\", activation_choices)\n",
    "optimizer = hp.choice(\"optimizer\", optimizer_choices)\n",
    "epochs = hp.choice(\"epochs\", epochs_choices)\n",
    "initializer = hp.choice(\"initializer\", initializer choices)\n",
    "#learning_rate = \n",
    "\n",
    "hyperspace = {\n",
    "    \"units_1\": nb_units_layer_1,\n",
    "    \"units_2\": nb_units_layer_2,\n",
    "    \"activation\": activation,\n",
    "    \"optimizer\": optimizer,\n",
    "    \"epochs\": epochs\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the hyperoptimization function\n",
    "def hyper_function(hyperspace_dict):\n",
    "    _, val_loss = model_trainer(**hyperspace_dict)\n",
    "    return {\"loss\": val_loss, \"status\": \"ok\"}\n",
    "\n",
    "# Serch for the best combination of parameters\n",
    "NB_TRIALS = 12\n",
    "best = fmin(fn=hyper_function, space=hyperspace, verbose=1, max_evals=NB_TRIALS, algo=tpe.suggest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the values of the best hyperparameters\n",
    "best_params = {\n",
    "    \"units_1\": best.get(\"units_1\"),\n",
    "    \"activation\": activation_choices[best.get(\"activation\")],\n",
    "    \"optimizer\": optimizer_choices[best.get(\"optimizer\")],\n",
    "    \"epochs\": epochs_choices[best.get(\"epochs\")]\n",
    "}\n",
    "\n",
    "# Generate the model with the best hyperparameters\n",
    "best_model, _ = model_trainer(**best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, we can generate Predictions\n",
    "y_tr_pred = best_model.predict(x_tr)\n",
    "y_val_pred = best_model.predict(x_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(x_tr[:,1], y_tr, label = \"Training Data\")\n",
    "plt.scatter(x_tr[:,1], y_tr_pred, color = \"red\", label = \"Training Prediction\")\n",
    "plt.scatter(x_val[:,1], y_val, label = \" Validation Data\")\n",
    "plt.scatter(x_val[:,1], y_val_pred, color = \"green\", label = \"Validation Prediction\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_constant_x(model, x_data, y_data):\n",
    "    for i, x in enumerate(x_data):\n",
    "        y = y_data[i]\n",
    "        x_grid = np.linspace(x[0], x[-1], 100)\n",
    "        y_pred = model(x_grid)\n",
    "        #import pdb; pdb.set_trace()\n",
    "        plt.plot(x_grid[:,1], y_pred, color=\"red\", label=\"Prediction\")\n",
    "        plt.scatter(x[:,1], y, color=\"blue\", label=\"Data\")\n",
    "        plt.legend()\n",
    "        plt.xlabel(\"$Q^2$ [GeV$^2$]\")\n",
    "        plt.ylabel(\"$F_2$\")\n",
    "        plt.title(f\"Prediction of $F_2$ at $x={x[0,0]}$\")\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_constant_x(best_model, x_data, y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "51b07192feadff41234e4986821c542e33f28bd852adab907add648296a24759"
  },
  "kernelspec": {
   "display_name": "nnpdf40",
   "language": "python",
   "name": "nnpdf40"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
