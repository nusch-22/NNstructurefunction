{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import yaml\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "from pathlib import Path\n",
    "from filetrials import FileTrials, space_eval\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.callbacks import Callback, EarlyStopping\n",
    "\n",
    "# Import hyperopt modules\n",
    "from hyperopt import hp, fmin, tpe\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix the seeds for reproducible results\n",
    "tf.random.set_seed(1234)\n",
    "np.random.seed(5678)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_path = Path().absolute()\n",
    "hyperopt_path = current_path\n",
    "fits_path = current_path / \"fits\"\n",
    "fits_path.mkdir(exist_ok=True)\n",
    "data_path = current_path / \"data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load runcard with parameters\n",
    "def load_runcard(filename):\n",
    "    with open(f\"{current_path}/\" + filename, \"r\") as file:\n",
    "        input_params = yaml.safe_load(file)\n",
    "    return input_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_mask(ndata, perc = 0.3):\n",
    "    mask = np.ones(ndata, dtype = int)\n",
    "    if ndata >= 3:\n",
    "        size_val = round(ndata*perc)\n",
    "        idx = np.random.choice(np.arange(1, ndata-1, 2), size_val, replace=False)\n",
    "        mask[idx] = 0\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(runcard):\n",
    "    df = pd.DataFrame()\n",
    "    filenames = os.listdir(f\"{data_path}\")\n",
    "    \n",
    "    for i, filename in enumerate(filenames):\n",
    "        with open(f\"{data_path}/\" + filename, \"r\") as file:\n",
    "            input_data = yaml.safe_load(file)\n",
    "            \n",
    "        x = input_data[\"x\"]\n",
    "        Q2 = np.array(input_data[\"Q2\"])\n",
    "        F_2 = np.array(input_data[\"F_2\"])\n",
    "        F_2_err_stat = np.array(input_data[\"F_2_err_stat\"])\n",
    "        F_2_err_sys = np.array(input_data[\"F_2_err_sys\"])\n",
    "\n",
    "        if runcard[\"Q2_cut\"] != None:\n",
    "            Q2_mask = np.where(Q2 < runcard[\"Q2_cut\"])\n",
    "            Q2 = Q2[Q2_mask]\n",
    "            F_2 = F_2[Q2_mask]\n",
    "            F_2_err_stat = F_2_err_stat[Q2_mask]\n",
    "            F_2_err_sys = F_2_err_sys[Q2_mask]\n",
    "\n",
    "        if i == 0:\n",
    "            ndata = len(Q2)\n",
    "            x_0 = np.repeat(x, ndata)\n",
    "            x_1 = Q2\n",
    "            y = F_2\n",
    "            y_err_stat = F_2_err_stat\n",
    "            y_err_sys = F_2_err_sys\n",
    "            mask = split_mask(ndata)\n",
    "            \n",
    "        else:\n",
    "            ndata = len(Q2)\n",
    "            x_0 = np.concatenate([x_0, np.repeat(x, ndata)])\n",
    "            x_1 = np.concatenate([x_1, Q2])\n",
    "            y = np.concatenate([y, F_2])\n",
    "            y_err_stat = np.concatenate([y_err_stat, F_2_err_stat])\n",
    "            y_err_sys = np.concatenate([y_err_sys, F_2_err_sys])\n",
    "            mask = np.concatenate([mask, split_mask(ndata)])\n",
    "            \n",
    "    df[\"x_0\"] = x_0\n",
    "    df[\"x_1\"] = x_1\n",
    "    df[\"y\"] = y\n",
    "    df[\"y_err_stat\"] = y_err_stat\n",
    "    df[\"y_err_sys\"] = y_err_sys\n",
    "    df[\"mask\"] = mask\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_trainer(data_df, runcard, **hyperparameters):\n",
    "    # Collect the values for the hyperparameters\n",
    "    optimizer = hyperparameters.get(\"optimizer\", \"adam\")\n",
    "    activation = hyperparameters.get(\"activation\", \"relu\")\n",
    "    epochs = hyperparameters.get(\"epochs\", 10)\n",
    "    nb_layers = hyperparameters.get(\"nb_layers\", (2, {'units_layer_1_2': 64, 'units_layer_2_2': 32}))\n",
    "    \n",
    "    layers = list(nb_layers[1].keys())\n",
    "    nb_units_1 = nb_layers[1][layers[0]]\n",
    "\n",
    "    # Construct the model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(units=nb_units_1, activation=activation, input_shape=[2])),\n",
    "    \n",
    "    if nb_layers[0] > 1:\n",
    "        for layer in layers[1:]:\n",
    "            model.add(Dense(units=nb_layers[1][layer], activation=activation))\n",
    "    \n",
    "    # output layer\n",
    "    model.add(Dense(units=1, activation=\"linear\"))\n",
    "\n",
    "    # Compile the Model as usual\n",
    "    model.compile(loss=\"mse\", optimizer=optimizer, metrics=[\"accuracy\"])\n",
    "\n",
    "    # Callbacks for Early Stopping\n",
    "    ES = EarlyStopping(\n",
    "        monitor=\"val_loss\",\n",
    "        mode=\"min\",\n",
    "        verbose=0,\n",
    "        patience=10,\n",
    "        restore_best_weights=True,\n",
    "    )\n",
    "    \n",
    "    # extract data\n",
    "    x_tr = data_df[data_df[\"mask\"]==1][[\"x_0\", \"x_1\"]].to_numpy()\n",
    "    x_val = data_df[data_df[\"mask\"]==0][[\"x_0\", \"x_1\"]].to_numpy()\n",
    "    y_tr = data_df[data_df[\"mask\"]==1][\"y\"].to_numpy()\n",
    "    y_val = data_df[data_df[\"mask\"]==0][\"y\"].to_numpy()\n",
    "    \n",
    "    # Fit the Model as usual\n",
    "    model.fit(\n",
    "        x_tr,\n",
    "        y_tr,\n",
    "        validation_data=(x_val, y_val),\n",
    "        epochs=100,\n",
    "        verbose=0,\n",
    "        callbacks=[ES]\n",
    "    )\n",
    "\n",
    "    # Evaluate the Model on the test. Note that this will be the\n",
    "    # parameter to hyperoptimize. If one wants, one could use x/y_tr.\n",
    "    # This might be ideal if one have very small number of datapoints\n",
    "    scores = model.evaluate(x_val, y_val, verbose=0)\n",
    "    # Return the value of the validation loss\n",
    "    return model, scores[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_layers_dict(runcard):\n",
    "    layers_list = []\n",
    "    nb_units_per_layer = runcard[\"nb_units_per_layer\"]\n",
    "    for n in runcard[\"layers_choices\"]:\n",
    "        layer_dict = {}\n",
    "        for i in range(1, n+1):\n",
    "            key = f\"units_layer_{i}_{n}\"\n",
    "            layer_dict[f\"units_layer_{i}\"] = hp.quniform(key, nb_units_per_layer[\"min\"], nb_units_per_layer[\"max\"], nb_units_per_layer[\"samples\"])\n",
    "        layers_list.append((n, layer_dict))\n",
    "    return hp.choice(\"nb_layers\", layers_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_hyperspace(runcard):\n",
    "    learning_rate_choices = runcard[\"learning_rate_choices\"]\n",
    "    activation = hp.choice(\"activation\", runcard[\"activation_choices\"])\n",
    "    optimizer = hp.choice(\"optimizer\", runcard[\"optimizer_choices\"])\n",
    "    epochs = hp.choice(\"epochs\", runcard[\"epochs_choices\"])\n",
    "    initializer = hp.choice(\"initializer\", runcard[\"initializer_choices\"])\n",
    "    learning_rate = hp.loguniform(\"learning_rate\", float(learning_rate_choices[\"min\"]), float(learning_rate_choices[\"max\"]))\n",
    "    nb_layers = construct_layers_dict(runcard)\n",
    "    \n",
    "    return {\n",
    "        \"activation\": activation,\n",
    "        \"optimizer\": optimizer,\n",
    "        \"epochs\": epochs,\n",
    "        \"initializer\": initializer,\n",
    "        \"learning_rate\": learning_rate,\n",
    "        \"nb_layers\": nb_layers\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_hyperopt(data_df, runcard):\n",
    "    hyperspace = define_hyperspace(runcard)\n",
    "\n",
    "    # Define the hyperoptimization function\n",
    "    def hyper_function(hyperspace_dict):\n",
    "        _, val_loss = model_trainer(data_df, runcard, **hyperspace_dict)\n",
    "        return {\"loss\": val_loss, \"status\": \"ok\"}\n",
    "\n",
    "    trials = FileTrials(hyperopt_path, parameters=hyperspace)\n",
    "    best = fmin(\n",
    "        fn=hyper_function,\n",
    "        space=hyperspace,\n",
    "        verbose=1,\n",
    "        max_evals=runcard[\"nb_trials\"],\n",
    "        algo=tpe.suggest,\n",
    "        trials=trials,\n",
    "    )\n",
    "    # Save the best hyperparameters combination in order to return it later\n",
    "    best_setup = space_eval(hyperspace, best)\n",
    "    # Write the output of the best into a file\n",
    "    with open(f\"{hyperopt_path}/best_hyperparameters.yaml\", \"w\") as file:\n",
    "        yaml.dump(best_setup, file, default_flow_style=False)\n",
    "    # Write the all the history of the hyperopt into a file\n",
    "    with open(f\"{hyperopt_path}/hyperopt_history.pickle\", \"wb\") as histfile:\n",
    "        pickle.dump(trials.trials, histfile)\n",
    "    return best_setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runcard = load_runcard(\"runcard.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = load_data(runcard)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_set = set(data_df[\"x_0\"])\n",
    "for x_value in x_set:\n",
    "    x_df = data_df[data_df[\"x_0\"]==x_value]\n",
    "    x = x_df[[\"x_0\", \"x_1\"]].to_numpy()\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = perform_hyperopt(data_df, runcard)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_constant_x(best_model, data_df):\n",
    "    # loop over x values\n",
    "    x_set = set(data_df[\"x_0\"])\n",
    "    for x_value in x_set:\n",
    "        x_df = data_df[data_df[\"x_0\"]==x_value]\n",
    "        x = x_df[[\"x_0\", \"x_1\"]].to_numpy()\n",
    "        y = x_df[\"y\"].to_numpy()\n",
    "        x_grid = np.linspace(x[0], x[-1], 100)\n",
    "        y_pred = best_model(x_grid)\n",
    "        \n",
    "        fig, ax = plt.subplots(1, 1) \n",
    "        ax.plot(x_grid[:, 1], y_pred, color=\"red\", label=\"Prediction\")\n",
    "        ax.scatter(x[:, 1], y, color=\"blue\", label=\"Data\")\n",
    "        ax.legend()\n",
    "        ax.set_xlabel(\"$Q^2$ [GeV$^2$]\")\n",
    "        ax.set_ylabel(\"$F_2$\")\n",
    "        ax.set_title(f\"Prediction of $F_2$ at $x={x[0,0]}$\")\n",
    "        plt.show()\n",
    "        plt.savefig(f\"{fits_path}/FIT_{x[0,0]}.png\")\n",
    "        ax.clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model,_ = model_trainer(data_df, runcard, **best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_constant_x(best_model, data_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_replicas(data_df, runcard):\n",
    "    n_rep = runcard[\"nb_replicas\"]\n",
    "    \n",
    "    y = data_df[\"y\"].to_numpy()\n",
    "    y_err = data_df[\"y_err_sys\"].to_numpy() + data_df[\"y_err_stat\"].to_numpy()\n",
    "    y_dist = np.zeros((n_rep, y.shape[0]))\n",
    "    for i, mean in enumerate(y):\n",
    "        y_dist[:, i] = np.random.normal(\n",
    "            loc=mean,\n",
    "            scale=(y_err[i]),\n",
    "            size=n_rep,\n",
    "        ) \n",
    "        \n",
    "    return y_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_replicas(data_df, runcard):\n",
    "    y_dist = create_replicas(data_df, runcard)\n",
    "    models = []\n",
    "    \n",
    "    for y in y_dist:\n",
    "        new_data_df = data_df.copy()\n",
    "        new_data_df[\"y\"] = y\n",
    "        best_model,_ = model_trainer(data_df, runcard, **best_params)\n",
    "        models.append(best_model)\n",
    "    \n",
    "    return models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_with_reps(models, data_df):\n",
    "    # loop over x values\n",
    "    x_set = set(data_df[\"x_0\"])\n",
    "    for x_value in x_set:\n",
    "        x_df = data_df[data_df[\"x_0\"]==x_value]\n",
    "        x = x_df[[\"x_0\", \"x_1\"]].to_numpy()\n",
    "        y = x_df[\"y\"].to_numpy()\n",
    "        y_err = x_df[\"y_err_stat\"].to_numpy() + x_df[\"y_err_sys\"].to_numpy()\n",
    "        x_grid = np.linspace(x[0], x[-1], 100)\n",
    "        \n",
    "        # loop over replicas\n",
    "        y_pred = []\n",
    "        for model in models:\n",
    "            y_pred.append(model.predict(x_grid))\n",
    "        \n",
    "        # compute mean and errorbands\n",
    "        p1_high = np.nanpercentile(y_pred,84,axis=0)\n",
    "        p1_low = np.nanpercentile(y_pred,16,axis=0)\n",
    "        p1_mid = (p1_high + p1_low )/2.\n",
    "        p1_error = (p1_high - p1_low )/2.\n",
    "        \n",
    "        p1_mid = p1_mid.reshape(-1)\n",
    "        p1_error = p1_error.reshape(-1)\n",
    "        \n",
    "        # plot\n",
    "        fig, ax = plt.subplots(1, 1) \n",
    "        ax.errorbar(x[:, 1], y, yerr=y_err, label = \"Data\", fmt=\"ko\", capsize=5)\n",
    "        ax.fill_between(x_grid[:, 1], y1=p1_mid-p1_error, y2=p1_mid+p1_error, color=\"red\", edgecolor=\"red\", label=\"Prediction\", alpha=0.25)\n",
    "        ax.plot(x_grid[:, 1], p1_mid, color=\"red\", linestyle=\"dashed\")\n",
    "        ax.legend()\n",
    "        ax.set_xlabel(\"$Q^2$ [GeV$^2$]\")\n",
    "        ax.set_ylabel(\"$F_2$\")\n",
    "        ax.set_title(f\"Prediction of $F_2$ at $x={x[0,0]}$\")\n",
    "        plt.show()\n",
    "        plt.savefig(f\"{fits_path}/FIT_{x[0,0]}.png\")\n",
    "        ax.clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = fit_replicas(data_df, runcard)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_with_reps(models, data_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ToDo:\n",
    "- write data_dict to file and read that again\n",
    "- !!python/tuple in best_hyperparameters.yaml now deleted by hand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "51b07192feadff41234e4986821c542e33f28bd852adab907add648296a24759"
  },
  "kernelspec": {
   "display_name": "nnpdf40",
   "language": "python",
   "name": "nnpdf40"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
