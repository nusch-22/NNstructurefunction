{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import yaml\n",
    "import os\n",
    "\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.callbacks import Callback, EarlyStopping\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q2_cut = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_trval(x_data, y_data, perc = 0.3):\n",
    "    size_val = round(x_data.shape[0]*perc)\n",
    "    if size_val > 0:\n",
    "        idx = np.random.choice(np.arange(1, x_data.shape[0]-1, 2), size_val, replace=False)\n",
    "        x_val = x_data[idx]\n",
    "        y_val = y_data[idx]\n",
    "        x_tr = np.delete(x_data, idx, axis = 0)\n",
    "        y_tr = np.delete(y_data, idx)\n",
    "    else:\n",
    "        x_tr = x_data\n",
    "        y_tr = y_data\n",
    "        x_val = None\n",
    "        y_val = None\n",
    "    return x_tr, y_tr, x_val, y_val, size_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "filenames = os.listdir(\"./data\")\n",
    "filenames = [\"DATA_CHORUS_0.02.yaml\", \"DATA_CHORUS_0.045.yaml\"]\n",
    "\n",
    "for i, filename in enumerate(filenames):\n",
    "    with open(\"./data/\" + filename, \"r\") as file:\n",
    "        input_data = yaml.safe_load(file)\n",
    "    \n",
    "    x = input_data[\"x\"]\n",
    "    Q2 = np.array(input_data[\"Q2\"])\n",
    "    F_2 = np.array(input_data[\"F_2\"])\n",
    "    \n",
    "    Q2_mask = np.where(Q2<Q2_cut)\n",
    "    Q2 = Q2[Q2_mask]\n",
    "    F_2 = F_2[Q2_mask]\n",
    "    \n",
    "    if i == 0:\n",
    "        x_data = np.zeros((len(Q2), 2))\n",
    "        x_data[:, 0] = x\n",
    "        x_data[:, 1] = Q2 \n",
    "        y_data = F_2\n",
    "        x_tr, y_tr, x_val, y_val, size_val = split_trval(x_data, y_data)\n",
    "    else:\n",
    "        x_data = np.zeros((len(Q2), 2))\n",
    "        x_data[:, 0] = x\n",
    "        x_data[:, 1] = Q2 \n",
    "        y_data = F_2\n",
    "        x_tr_new, y_tr_new, x_val_new, y_val_new, size_val = split_trval(x_data, y_data)\n",
    "        \n",
    "        x_tr = np.concatenate([x_tr, x_tr_new], axis = 0)\n",
    "        y_tr = np.concatenate([y_tr, y_tr_new], axis = 0)\n",
    "        if size_val != 0:\n",
    "            x_val = np.concatenate([x_val, x_val_new], axis = 0)\n",
    "            y_val = np.concatenate([y_val, y_val_new], axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_36 (Dense)             (None, 1)                 3         \n",
      "_________________________________________________________________\n",
      "dense_37 (Dense)             (None, 32)                64        \n",
      "_________________________________________________________________\n",
      "dense_38 (Dense)             (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dense_39 (Dense)             (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 1,156\n",
      "Trainable params: 1,156\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Create the NN model\n",
    "model = Sequential()\n",
    "model.add(Dense(units = 1, activation = 'linear', input_shape=[2]))\n",
    "model.add(Dense(units = 32, activation = 'relu'))\n",
    "model.add(Dense(units = 32, activation = 'relu'))\n",
    "model.add(Dense(units = 1, activation = 'linear'))\n",
    "model.compile(loss='mse', optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "# Display the model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "8/8 [==============================] - 1s 80ms/step - loss: 0.9150 - accuracy: 0.0000e+00 - val_loss: 0.7473 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.4482 - accuracy: 0.0000e+00 - val_loss: 0.4971 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.4636 - accuracy: 0.0000e+00 - val_loss: 0.4004 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.3708 - accuracy: 0.0000e+00 - val_loss: 0.3997 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.3458 - accuracy: 0.0000e+00 - val_loss: 0.3897 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.2889 - accuracy: 0.0000e+00 - val_loss: 0.3323 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.3264 - accuracy: 0.0000e+00 - val_loss: 0.3488 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.3070 - accuracy: 0.0000e+00 - val_loss: 0.3414 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.2182 - accuracy: 0.0000e+00 - val_loss: 0.3013 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.3056 - accuracy: 0.0000e+00 - val_loss: 0.2847 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.1844 - accuracy: 0.0000e+00 - val_loss: 0.2461 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/1000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.2426 - accuracy: 0.0000e+00 - val_loss: 0.2514 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/1000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.1748 - accuracy: 0.0000e+00 - val_loss: 0.2375 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.2314 - accuracy: 0.0000e+00 - val_loss: 0.2163 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/1000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.1879 - accuracy: 0.0000e+00 - val_loss: 0.2018 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.1658 - accuracy: 0.0000e+00 - val_loss: 0.1520 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.1407 - accuracy: 0.0000e+00 - val_loss: 0.1522 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/1000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0951 - accuracy: 0.0000e+00 - val_loss: 0.1437 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1106 - accuracy: 0.0000e+00 - val_loss: 0.1497 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.1211 - accuracy: 0.0000e+00 - val_loss: 0.1550 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0824 - accuracy: 0.0000e+00 - val_loss: 0.1307 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0702 - accuracy: 0.0000e+00 - val_loss: 0.1048 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/1000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0608 - accuracy: 0.0000e+00 - val_loss: 0.0893 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0665 - accuracy: 0.0000e+00 - val_loss: 0.0917 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/1000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0737 - accuracy: 0.0000e+00 - val_loss: 0.0847 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/1000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0787 - accuracy: 0.0000e+00 - val_loss: 0.0773 - val_accuracy: 0.0000e+00\n",
      "Epoch 27/1000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0714 - accuracy: 0.0000e+00 - val_loss: 0.0692 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/1000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0486 - accuracy: 0.0000e+00 - val_loss: 0.0604 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0628 - accuracy: 0.0000e+00 - val_loss: 0.0574 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0329 - accuracy: 0.0000e+00 - val_loss: 0.0477 - val_accuracy: 0.0000e+00\n",
      "Epoch 31/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0203 - accuracy: 0.0000e+00 - val_loss: 0.0434 - val_accuracy: 0.0000e+00\n",
      "Epoch 32/1000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0286 - accuracy: 0.0000e+00 - val_loss: 0.0374 - val_accuracy: 0.0000e+00\n",
      "Epoch 33/1000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0192 - accuracy: 0.0000e+00 - val_loss: 0.0401 - val_accuracy: 0.0000e+00\n",
      "Epoch 34/1000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0211 - accuracy: 0.0000e+00 - val_loss: 0.0343 - val_accuracy: 0.0000e+00\n",
      "Epoch 35/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0169 - accuracy: 0.0000e+00 - val_loss: 0.0356 - val_accuracy: 0.0000e+00\n",
      "Epoch 36/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0244 - accuracy: 0.0000e+00 - val_loss: 0.0286 - val_accuracy: 0.0000e+00\n",
      "Epoch 37/1000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0246 - accuracy: 0.0000e+00 - val_loss: 0.0262 - val_accuracy: 0.0000e+00\n",
      "Epoch 38/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0156 - accuracy: 0.0000e+00 - val_loss: 0.0190 - val_accuracy: 0.0000e+00\n",
      "Epoch 39/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0182 - accuracy: 0.0000e+00 - val_loss: 0.0258 - val_accuracy: 0.0000e+00\n",
      "Epoch 40/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0163 - accuracy: 0.0000e+00 - val_loss: 0.0191 - val_accuracy: 0.0000e+00\n",
      "Epoch 41/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0192 - accuracy: 0.0000e+00 - val_loss: 0.0217 - val_accuracy: 0.0000e+00\n",
      "Epoch 42/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0127 - accuracy: 0.0000e+00 - val_loss: 0.0168 - val_accuracy: 0.0000e+00\n",
      "Epoch 43/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0086 - accuracy: 0.0000e+00 - val_loss: 0.0134 - val_accuracy: 0.0000e+00\n",
      "Epoch 44/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0075 - accuracy: 0.0000e+00 - val_loss: 0.0143 - val_accuracy: 0.0000e+00\n",
      "Epoch 45/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0065 - accuracy: 0.0000e+00 - val_loss: 0.0161 - val_accuracy: 0.0000e+00\n",
      "Epoch 46/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0081 - accuracy: 0.0000e+00 - val_loss: 0.0139 - val_accuracy: 0.0000e+00\n",
      "Epoch 47/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0091 - accuracy: 0.0000e+00 - val_loss: 0.0137 - val_accuracy: 0.0000e+00\n",
      "Epoch 48/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0073 - accuracy: 0.0000e+00 - val_loss: 0.0107 - val_accuracy: 0.0000e+00\n",
      "Epoch 49/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0101 - accuracy: 0.0000e+00 - val_loss: 0.0115 - val_accuracy: 0.0000e+00\n",
      "Epoch 50/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0089 - accuracy: 0.0000e+00 - val_loss: 0.0139 - val_accuracy: 0.0000e+00\n",
      "Epoch 51/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0068 - accuracy: 0.0000e+00 - val_loss: 0.0106 - val_accuracy: 0.0000e+00\n",
      "Epoch 52/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0062 - accuracy: 0.0000e+00 - val_loss: 0.0095 - val_accuracy: 0.0000e+00\n",
      "Epoch 53/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0049 - accuracy: 0.0000e+00 - val_loss: 0.0075 - val_accuracy: 0.0000e+00\n",
      "Epoch 54/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0070 - accuracy: 0.0000e+00 - val_loss: 0.0114 - val_accuracy: 0.0000e+00\n",
      "Epoch 55/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0059 - accuracy: 0.0000e+00 - val_loss: 0.0101 - val_accuracy: 0.0000e+00\n",
      "Epoch 56/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0030 - accuracy: 0.0000e+00 - val_loss: 0.0089 - val_accuracy: 0.0000e+00\n",
      "Epoch 57/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0024 - accuracy: 0.0000e+00 - val_loss: 0.0077 - val_accuracy: 0.0000e+00\n",
      "Epoch 58/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0042 - accuracy: 0.0000e+00 - val_loss: 0.0076 - val_accuracy: 0.0000e+00\n",
      "Epoch 59/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0048 - accuracy: 0.0000e+00 - val_loss: 0.0095 - val_accuracy: 0.0000e+00\n",
      "Epoch 60/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0077 - accuracy: 0.0000e+00 - val_loss: 0.0087 - val_accuracy: 0.0000e+00\n",
      "Epoch 61/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0029 - accuracy: 0.0000e+00 - val_loss: 0.0092 - val_accuracy: 0.0000e+00\n",
      "Epoch 62/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0046 - accuracy: 0.0000e+00 - val_loss: 0.0061 - val_accuracy: 0.0000e+00\n",
      "Epoch 63/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0034 - accuracy: 0.0000e+00 - val_loss: 0.0068 - val_accuracy: 0.0000e+00\n",
      "Epoch 64/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0063 - accuracy: 0.0000e+00 - val_loss: 0.0076 - val_accuracy: 0.0000e+00\n",
      "Epoch 65/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0052 - accuracy: 0.0000e+00 - val_loss: 0.0083 - val_accuracy: 0.0000e+00\n",
      "Epoch 66/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0026 - accuracy: 0.0000e+00 - val_loss: 0.0061 - val_accuracy: 0.0000e+00\n",
      "Epoch 67/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0018 - accuracy: 0.0000e+00 - val_loss: 0.0056 - val_accuracy: 0.0000e+00\n",
      "Epoch 68/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0025 - accuracy: 0.0000e+00 - val_loss: 0.0074 - val_accuracy: 0.0000e+00\n",
      "Epoch 69/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0038 - accuracy: 0.0000e+00 - val_loss: 0.0064 - val_accuracy: 0.0000e+00\n",
      "Epoch 70/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0033 - accuracy: 0.0000e+00 - val_loss: 0.0062 - val_accuracy: 0.0000e+00\n",
      "Epoch 71/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0040 - accuracy: 0.0000e+00 - val_loss: 0.0065 - val_accuracy: 0.0000e+00\n",
      "Epoch 72/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0033 - accuracy: 0.0000e+00 - val_loss: 0.0062 - val_accuracy: 0.0000e+00\n",
      "Epoch 73/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0036 - accuracy: 0.0000e+00 - val_loss: 0.0055 - val_accuracy: 0.0000e+00\n",
      "Epoch 74/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0026 - accuracy: 0.0000e+00 - val_loss: 0.0050 - val_accuracy: 0.0000e+00\n",
      "Epoch 75/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0033 - accuracy: 0.0000e+00 - val_loss: 0.0067 - val_accuracy: 0.0000e+00\n",
      "Epoch 76/1000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0026 - accuracy: 0.0000e+00 - val_loss: 0.0054 - val_accuracy: 0.0000e+00\n",
      "Epoch 77/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0025 - accuracy: 0.0000e+00 - val_loss: 0.0057 - val_accuracy: 0.0000e+00\n",
      "Epoch 78/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0040 - accuracy: 0.0000e+00 - val_loss: 0.0054 - val_accuracy: 0.0000e+00\n",
      "Epoch 79/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0015 - accuracy: 0.0000e+00 - val_loss: 0.0048 - val_accuracy: 0.0000e+00\n",
      "Epoch 80/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0026 - accuracy: 0.0000e+00 - val_loss: 0.0062 - val_accuracy: 0.0000e+00\n",
      "Epoch 81/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0024 - accuracy: 0.0000e+00 - val_loss: 0.0052 - val_accuracy: 0.0000e+00\n",
      "Epoch 82/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0031 - accuracy: 0.0000e+00 - val_loss: 0.0047 - val_accuracy: 0.0000e+00\n",
      "Epoch 83/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0018 - accuracy: 0.0000e+00 - val_loss: 0.0055 - val_accuracy: 0.0000e+00\n",
      "Epoch 84/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0021 - accuracy: 0.0000e+00 - val_loss: 0.0053 - val_accuracy: 0.0000e+00\n",
      "Epoch 85/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0029 - accuracy: 0.0000e+00 - val_loss: 0.0045 - val_accuracy: 0.0000e+00\n",
      "Epoch 86/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0030 - accuracy: 0.0000e+00 - val_loss: 0.0055 - val_accuracy: 0.0000e+00\n",
      "Epoch 87/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0023 - accuracy: 0.0000e+00 - val_loss: 0.0051 - val_accuracy: 0.0000e+00\n",
      "Epoch 88/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0024 - accuracy: 0.0000e+00 - val_loss: 0.0045 - val_accuracy: 0.0000e+00\n",
      "Epoch 89/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0033 - accuracy: 0.0000e+00 - val_loss: 0.0046 - val_accuracy: 0.0000e+00\n",
      "Epoch 90/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0027 - accuracy: 0.0000e+00 - val_loss: 0.0053 - val_accuracy: 0.0000e+00\n",
      "Epoch 91/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0018 - accuracy: 0.0000e+00 - val_loss: 0.0059 - val_accuracy: 0.0000e+00\n",
      "Epoch 92/1000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0031 - accuracy: 0.0000e+00 - val_loss: 0.0038 - val_accuracy: 0.0000e+00\n",
      "Epoch 93/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0030 - accuracy: 0.0000e+00 - val_loss: 0.0056 - val_accuracy: 0.0000e+00\n",
      "Epoch 94/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0019 - accuracy: 0.0000e+00 - val_loss: 0.0045 - val_accuracy: 0.0000e+00\n",
      "Epoch 95/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0021 - accuracy: 0.0000e+00 - val_loss: 0.0032 - val_accuracy: 0.0000e+00\n",
      "Epoch 96/1000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0026 - accuracy: 0.0000e+00 - val_loss: 0.0047 - val_accuracy: 0.0000e+00\n",
      "Epoch 97/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0030 - accuracy: 0.0000e+00 - val_loss: 0.0045 - val_accuracy: 0.0000e+00\n",
      "Epoch 98/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0020 - accuracy: 0.0000e+00 - val_loss: 0.0046 - val_accuracy: 0.0000e+00\n",
      "Epoch 99/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0033 - accuracy: 0.0000e+00 - val_loss: 0.0037 - val_accuracy: 0.0000e+00\n",
      "Epoch 100/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0028 - accuracy: 0.0000e+00 - val_loss: 0.0037 - val_accuracy: 0.0000e+00\n",
      "Epoch 101/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0029 - accuracy: 0.0000e+00 - val_loss: 0.0045 - val_accuracy: 0.0000e+00\n",
      "Epoch 102/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0024 - accuracy: 0.0000e+00 - val_loss: 0.0047 - val_accuracy: 0.0000e+00\n",
      "Epoch 103/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0014 - accuracy: 0.0000e+00 - val_loss: 0.0047 - val_accuracy: 0.0000e+00\n",
      "Epoch 104/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0032 - accuracy: 0.0000e+00 - val_loss: 0.0029 - val_accuracy: 0.0000e+00\n",
      "Epoch 105/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0026 - accuracy: 0.0000e+00 - val_loss: 0.0058 - val_accuracy: 0.0000e+00\n",
      "Epoch 106/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0022 - accuracy: 0.0000e+00 - val_loss: 0.0038 - val_accuracy: 0.0000e+00\n",
      "Epoch 107/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0023 - accuracy: 0.0000e+00 - val_loss: 0.0037 - val_accuracy: 0.0000e+00\n",
      "Epoch 108/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0020 - accuracy: 0.0000e+00 - val_loss: 0.0034 - val_accuracy: 0.0000e+00\n",
      "Epoch 109/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0024 - accuracy: 0.0000e+00 - val_loss: 0.0049 - val_accuracy: 0.0000e+00\n",
      "Epoch 110/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0024 - accuracy: 0.0000e+00 - val_loss: 0.0036 - val_accuracy: 0.0000e+00\n",
      "Epoch 111/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0025 - accuracy: 0.0000e+00 - val_loss: 0.0033 - val_accuracy: 0.0000e+00\n",
      "Epoch 112/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0024 - accuracy: 0.0000e+00 - val_loss: 0.0040 - val_accuracy: 0.0000e+00\n",
      "Epoch 113/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0020 - accuracy: 0.0000e+00 - val_loss: 0.0050 - val_accuracy: 0.0000e+00\n",
      "Epoch 114/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0025 - accuracy: 0.0000e+00 - val_loss: 0.0029 - val_accuracy: 0.0000e+00\n",
      "Epoch 115/1000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0027 - accuracy: 0.0000e+00 - val_loss: 0.0031 - val_accuracy: 0.0000e+00\n",
      "Epoch 116/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0022 - accuracy: 0.0000e+00 - val_loss: 0.0045 - val_accuracy: 0.0000e+00\n",
      "Epoch 117/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0036 - accuracy: 0.0000e+00 - val_loss: 0.0033 - val_accuracy: 0.0000e+00\n",
      "Epoch 118/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0025 - accuracy: 0.0000e+00 - val_loss: 0.0028 - val_accuracy: 0.0000e+00\n",
      "Epoch 119/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0024 - accuracy: 0.0000e+00 - val_loss: 0.0047 - val_accuracy: 0.0000e+00\n",
      "Epoch 120/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0016 - accuracy: 0.0000e+00 - val_loss: 0.0037 - val_accuracy: 0.0000e+00\n",
      "Epoch 121/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0012 - accuracy: 0.0000e+00 - val_loss: 0.0032 - val_accuracy: 0.0000e+00\n",
      "Epoch 122/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0019 - accuracy: 0.0000e+00 - val_loss: 0.0025 - val_accuracy: 0.0000e+00\n",
      "Epoch 123/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0022 - accuracy: 0.0000e+00 - val_loss: 0.0036 - val_accuracy: 0.0000e+00\n",
      "Epoch 124/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0016 - accuracy: 0.0000e+00 - val_loss: 0.0039 - val_accuracy: 0.0000e+00\n",
      "Epoch 125/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0018 - accuracy: 0.0000e+00 - val_loss: 0.0030 - val_accuracy: 0.0000e+00\n",
      "Epoch 126/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0024 - accuracy: 0.0000e+00 - val_loss: 0.0028 - val_accuracy: 0.0000e+00\n",
      "Epoch 127/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0022 - accuracy: 0.0000e+00 - val_loss: 0.0045 - val_accuracy: 0.0000e+00\n",
      "Epoch 128/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0027 - accuracy: 0.0000e+00 - val_loss: 0.0036 - val_accuracy: 0.0000e+00\n",
      "Epoch 129/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0029 - accuracy: 0.0000e+00 - val_loss: 0.0023 - val_accuracy: 0.0000e+00\n",
      "Epoch 130/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0022 - accuracy: 0.0000e+00 - val_loss: 0.0031 - val_accuracy: 0.0000e+00\n",
      "Epoch 131/1000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0026 - accuracy: 0.0000e+00 - val_loss: 0.0039 - val_accuracy: 0.0000e+00\n",
      "Epoch 132/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0012 - accuracy: 0.0000e+00 - val_loss: 0.0037 - val_accuracy: 0.0000e+00\n",
      "Epoch 133/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0015 - accuracy: 0.0000e+00 - val_loss: 0.0028 - val_accuracy: 0.0000e+00\n",
      "Epoch 134/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0029 - accuracy: 0.0000e+00 - val_loss: 0.0024 - val_accuracy: 0.0000e+00\n",
      "Epoch 135/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0020 - accuracy: 0.0000e+00 - val_loss: 0.0042 - val_accuracy: 0.0000e+00\n",
      "Epoch 136/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0020 - accuracy: 0.0000e+00 - val_loss: 0.0029 - val_accuracy: 0.0000e+00\n",
      "Epoch 137/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0020 - accuracy: 0.0000e+00 - val_loss: 0.0026 - val_accuracy: 0.0000e+00\n",
      "Epoch 138/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0019 - accuracy: 0.0000e+00 - val_loss: 0.0043 - val_accuracy: 0.0000e+00\n",
      "Epoch 139/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0029 - accuracy: 0.0000e+00 - val_loss: 0.0026 - val_accuracy: 0.0000e+00\n",
      "Epoch 140/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0021 - accuracy: 0.0000e+00 - val_loss: 0.0032 - val_accuracy: 0.0000e+00\n",
      "Epoch 141/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0016 - accuracy: 0.0000e+00 - val_loss: 0.0038 - val_accuracy: 0.0000e+00\n",
      "Epoch 142/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0010 - accuracy: 0.0000e+00 - val_loss: 0.0030 - val_accuracy: 0.0000e+00\n",
      "Epoch 143/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0025 - accuracy: 0.0000e+00 - val_loss: 0.0025 - val_accuracy: 0.0000e+00\n",
      "Epoch 144/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0020 - accuracy: 0.0000e+00 - val_loss: 0.0043 - val_accuracy: 0.0000e+00\n",
      "Epoch 145/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0034 - accuracy: 0.0000e+00 - val_loss: 0.0023 - val_accuracy: 0.0000e+00\n",
      "Epoch 146/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0021 - accuracy: 0.0000e+00 - val_loss: 0.0025 - val_accuracy: 0.0000e+00\n",
      "Epoch 147/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0016 - accuracy: 0.0000e+00 - val_loss: 0.0048 - val_accuracy: 0.0000e+00\n",
      "Epoch 148/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0024 - accuracy: 0.0000e+00 - val_loss: 0.0032 - val_accuracy: 0.0000e+00\n",
      "Epoch 149/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0021 - accuracy: 0.0000e+00 - val_loss: 0.0023 - val_accuracy: 0.0000e+00\n",
      "Epoch 150/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0012 - accuracy: 0.0000e+00 - val_loss: 0.0040 - val_accuracy: 0.0000e+00\n",
      "Epoch 151/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0020 - accuracy: 0.0000e+00 - val_loss: 0.0032 - val_accuracy: 0.0000e+00\n",
      "Epoch 152/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0022 - accuracy: 0.0000e+00 - val_loss: 0.0031 - val_accuracy: 0.0000e+00\n",
      "Epoch 153/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0022 - accuracy: 0.0000e+00 - val_loss: 0.0035 - val_accuracy: 0.0000e+00\n",
      "Epoch 154/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0015 - accuracy: 0.0000e+00 - val_loss: 0.0034 - val_accuracy: 0.0000e+00\n",
      "Epoch 155/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0013 - accuracy: 0.0000e+00 - val_loss: 0.0033 - val_accuracy: 0.0000e+00\n",
      "Epoch 156/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0012 - accuracy: 0.0000e+00 - val_loss: 0.0029 - val_accuracy: 0.0000e+00\n",
      "Epoch 157/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0018 - accuracy: 0.0000e+00 - val_loss: 0.0021 - val_accuracy: 0.0000e+00\n",
      "Epoch 158/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0018 - accuracy: 0.0000e+00 - val_loss: 0.0053 - val_accuracy: 0.0000e+00\n",
      "Epoch 159/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 9.7718e-04 - accuracy: 0.0000e+00 - val_loss: 0.0027 - val_accuracy: 0.0000e+00\n",
      "Epoch 160/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0016 - accuracy: 0.0000e+00 - val_loss: 0.0034 - val_accuracy: 0.0000e+00\n",
      "Epoch 161/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0014 - accuracy: 0.0000e+00 - val_loss: 0.0032 - val_accuracy: 0.0000e+00\n",
      "Epoch 162/1000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0018 - accuracy: 0.0000e+00 - val_loss: 0.0026 - val_accuracy: 0.0000e+00\n",
      "Epoch 163/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0014 - accuracy: 0.0000e+00 - val_loss: 0.0051 - val_accuracy: 0.0000e+00\n",
      "Epoch 164/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 9.4876e-04 - accuracy: 0.0000e+00 - val_loss: 0.0035 - val_accuracy: 0.0000e+00\n",
      "Epoch 165/1000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0011 - accuracy: 0.0000e+00 - val_loss: 0.0022 - val_accuracy: 0.0000e+00\n",
      "Epoch 166/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0024 - accuracy: 0.0000e+00 - val_loss: 0.0032 - val_accuracy: 0.0000e+00\n",
      "Epoch 167/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0014 - accuracy: 0.0000e+00 - val_loss: 0.0050 - val_accuracy: 0.0000e+00\n",
      "Epoch 168/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0012 - accuracy: 0.0000e+00 - val_loss: 0.0017 - val_accuracy: 0.0000e+00\n",
      "Epoch 169/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0027 - accuracy: 0.0000e+00 - val_loss: 0.0037 - val_accuracy: 0.0000e+00\n",
      "Epoch 170/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0023 - accuracy: 0.0000e+00 - val_loss: 0.0047 - val_accuracy: 0.0000e+00\n",
      "Epoch 171/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0020 - accuracy: 0.0000e+00 - val_loss: 0.0021 - val_accuracy: 0.0000e+00\n",
      "Epoch 172/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0023 - accuracy: 0.0000e+00 - val_loss: 0.0038 - val_accuracy: 0.0000e+00\n",
      "Epoch 173/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 8.0595e-04 - accuracy: 0.0000e+00 - val_loss: 0.0036 - val_accuracy: 0.0000e+00\n",
      "Epoch 174/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0014 - accuracy: 0.0000e+00 - val_loss: 0.0028 - val_accuracy: 0.0000e+00\n",
      "Epoch 175/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0025 - accuracy: 0.0000e+00 - val_loss: 0.0033 - val_accuracy: 0.0000e+00\n",
      "Epoch 176/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0014 - accuracy: 0.0000e+00 - val_loss: 0.0044 - val_accuracy: 0.0000e+00\n",
      "Epoch 177/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0041 - accuracy: 0.0000e+00 - val_loss: 0.0024 - val_accuracy: 0.0000e+00\n",
      "Epoch 178/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0029 - accuracy: 0.0000e+00 - val_loss: 0.0045 - val_accuracy: 0.0000e+00\n",
      "Epoch 179/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0015 - accuracy: 0.0000e+00 - val_loss: 0.0024 - val_accuracy: 0.0000e+00\n",
      "Epoch 180/1000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0021 - accuracy: 0.0000e+00 - val_loss: 0.0030 - val_accuracy: 0.0000e+00\n",
      "Epoch 181/1000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0020 - accuracy: 0.0000e+00 - val_loss: 0.0040 - val_accuracy: 0.0000e+00\n",
      "Epoch 182/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 9.8960e-04 - accuracy: 0.0000e+00 - val_loss: 0.0025 - val_accuracy: 0.0000e+00\n",
      "Epoch 183/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0026 - accuracy: 0.0000e+00 - val_loss: 0.0018 - val_accuracy: 0.0000e+00\n",
      "Epoch 184/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0027 - accuracy: 0.0000e+00 - val_loss: 0.0086 - val_accuracy: 0.0000e+00\n",
      "Epoch 185/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0047 - accuracy: 0.0000e+00 - val_loss: 0.0013 - val_accuracy: 0.0000e+00\n",
      "Epoch 186/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0052 - accuracy: 0.0000e+00 - val_loss: 0.0024 - val_accuracy: 0.0000e+00\n",
      "Epoch 187/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0016 - accuracy: 0.0000e+00 - val_loss: 0.0042 - val_accuracy: 0.0000e+00\n",
      "Epoch 188/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0016 - accuracy: 0.0000e+00 - val_loss: 0.0041 - val_accuracy: 0.0000e+00\n",
      "Epoch 189/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0045 - accuracy: 0.0000e+00 - val_loss: 0.0021 - val_accuracy: 0.0000e+00\n",
      "Epoch 190/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0030 - accuracy: 0.0000e+00 - val_loss: 0.0061 - val_accuracy: 0.0000e+00\n",
      "Epoch 191/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0020 - accuracy: 0.0000e+00 - val_loss: 0.0025 - val_accuracy: 0.0000e+00\n",
      "Epoch 192/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0027 - accuracy: 0.0000e+00 - val_loss: 0.0030 - val_accuracy: 0.0000e+00\n",
      "Epoch 193/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0020 - accuracy: 0.0000e+00 - val_loss: 0.0036 - val_accuracy: 0.0000e+00\n",
      "Epoch 194/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 7.9153e-04 - accuracy: 0.0000e+00 - val_loss: 0.0035 - val_accuracy: 0.0000e+00\n",
      "Epoch 195/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0023 - accuracy: 0.0000e+00 - val_loss: 0.0023 - val_accuracy: 0.0000e+00\n",
      "Epoch 196/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0022 - accuracy: 0.0000e+00 - val_loss: 0.0047 - val_accuracy: 0.0000e+00\n",
      "Epoch 197/1000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0022 - accuracy: 0.0000e+00 - val_loss: 0.0026 - val_accuracy: 0.0000e+00\n",
      "Epoch 198/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0023 - accuracy: 0.0000e+00 - val_loss: 0.0026 - val_accuracy: 0.0000e+00\n",
      "Epoch 199/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0016 - accuracy: 0.0000e+00 - val_loss: 0.0040 - val_accuracy: 0.0000e+00\n",
      "Epoch 200/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0012 - accuracy: 0.0000e+00 - val_loss: 0.0022 - val_accuracy: 0.0000e+00\n",
      "Epoch 201/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0016 - accuracy: 0.0000e+00 - val_loss: 0.0038 - val_accuracy: 0.0000e+00\n",
      "Epoch 202/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0013 - accuracy: 0.0000e+00 - val_loss: 0.0030 - val_accuracy: 0.0000e+00\n",
      "Epoch 203/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0012 - accuracy: 0.0000e+00 - val_loss: 0.0020 - val_accuracy: 0.0000e+00\n",
      "Epoch 204/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0015 - accuracy: 0.0000e+00 - val_loss: 0.0029 - val_accuracy: 0.0000e+00\n",
      "Epoch 205/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0022 - accuracy: 0.0000e+00 - val_loss: 0.0048 - val_accuracy: 0.0000e+00\n",
      "Epoch 206/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0012 - accuracy: 0.0000e+00 - val_loss: 0.0021 - val_accuracy: 0.0000e+00\n",
      "Epoch 207/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0024 - accuracy: 0.0000e+00 - val_loss: 0.0026 - val_accuracy: 0.0000e+00\n",
      "Epoch 208/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0017 - accuracy: 0.0000e+00 - val_loss: 0.0047 - val_accuracy: 0.0000e+00\n",
      "Epoch 209/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0015 - accuracy: 0.0000e+00 - val_loss: 0.0021 - val_accuracy: 0.0000e+00\n",
      "Epoch 210/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0041 - accuracy: 0.0000e+00 - val_loss: 0.0057 - val_accuracy: 0.0000e+00\n",
      "Epoch 211/1000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0025 - accuracy: 0.0000e+00 - val_loss: 0.0027 - val_accuracy: 0.0000e+00\n",
      "Epoch 212/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0017 - accuracy: 0.0000e+00 - val_loss: 0.0029 - val_accuracy: 0.0000e+00\n",
      "Epoch 213/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0019 - accuracy: 0.0000e+00 - val_loss: 0.0034 - val_accuracy: 0.0000e+00\n",
      "Epoch 214/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0021 - accuracy: 0.0000e+00 - val_loss: 0.0032 - val_accuracy: 0.0000e+00\n",
      "Epoch 215/1000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0017 - accuracy: 0.0000e+00 - val_loss: 0.0034 - val_accuracy: 0.0000e+00\n",
      "Epoch 216/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0013 - accuracy: 0.0000e+00 - val_loss: 0.0029 - val_accuracy: 0.0000e+00\n",
      "Epoch 217/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0017 - accuracy: 0.0000e+00 - val_loss: 0.0028 - val_accuracy: 0.0000e+00\n",
      "Epoch 218/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0012 - accuracy: 0.0000e+00 - val_loss: 0.0035 - val_accuracy: 0.0000e+00\n",
      "Epoch 219/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0011 - accuracy: 0.0000e+00 - val_loss: 0.0021 - val_accuracy: 0.0000e+00\n",
      "Epoch 220/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0027 - accuracy: 0.0000e+00 - val_loss: 0.0041 - val_accuracy: 0.0000e+00\n",
      "Epoch 221/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0013 - accuracy: 0.0000e+00 - val_loss: 0.0035 - val_accuracy: 0.0000e+00\n",
      "Epoch 222/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0011 - accuracy: 0.0000e+00 - val_loss: 0.0024 - val_accuracy: 0.0000e+00\n",
      "Epoch 223/1000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0017 - accuracy: 0.0000e+00 - val_loss: 0.0038 - val_accuracy: 0.0000e+00\n",
      "Epoch 224/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 9.7702e-04 - accuracy: 0.0000e+00 - val_loss: 0.0040 - val_accuracy: 0.0000e+00\n",
      "Epoch 225/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0024 - accuracy: 0.0000e+00 - val_loss: 0.0024 - val_accuracy: 0.0000e+00\n",
      "Epoch 226/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0026 - accuracy: 0.0000e+00 - val_loss: 0.0061 - val_accuracy: 0.0000e+00\n",
      "Epoch 227/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0026 - accuracy: 0.0000e+00 - val_loss: 0.0020 - val_accuracy: 0.0000e+00\n",
      "Epoch 228/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0029 - accuracy: 0.0000e+00 - val_loss: 0.0014 - val_accuracy: 0.0000e+00\n",
      "Epoch 229/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0023 - accuracy: 0.0000e+00 - val_loss: 0.0023 - val_accuracy: 0.0000e+00\n",
      "Epoch 230/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0035 - accuracy: 0.0000e+00 - val_loss: 0.0084 - val_accuracy: 0.0000e+00\n",
      "Epoch 231/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0096 - accuracy: 0.0000e+00 - val_loss: 0.0017 - val_accuracy: 0.0000e+00\n",
      "Epoch 232/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0033 - accuracy: 0.0000e+00 - val_loss: 0.0030 - val_accuracy: 0.0000e+00\n",
      "Epoch 233/1000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0012 - accuracy: 0.0000e+00 - val_loss: 0.0031 - val_accuracy: 0.0000e+00\n",
      "Epoch 234/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0011 - accuracy: 0.0000e+00 - val_loss: 0.0018 - val_accuracy: 0.0000e+00\n",
      "Epoch 235/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0027 - accuracy: 0.0000e+00 - val_loss: 0.0040 - val_accuracy: 0.0000e+00\n",
      "Epoch 00235: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f2360171670>"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=50)\n",
    "model.fit(x_tr, y_tr, validation_data=(x_val ,y_val), epochs=1000, batch_size=1, verbose=1, callbacks=[es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_tr_pred = model.predict(x_tr)\n",
    "y_val_pred = model.predict(x_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f23487d1f40>"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(x_tr[:,1], y_tr, label = \"Training Data\")\n",
    "plt.scatter(x_tr[:,1], y_tr_pred, color = \"red\", label = \"Training Prediction\")\n",
    "plt.scatter(x_val[:,1], y_val, label = \" Validation Data\")\n",
    "plt.scatter(x_val[:,1], y_val_pred, color = \"green\", label = \"Validation Prediction\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "51b07192feadff41234e4986821c542e33f28bd852adab907add648296a24759"
  },
  "kernelspec": {
   "display_name": "nnpdf40",
   "language": "python",
   "name": "nnpdf40"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
